{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oplossingen_huiswerk.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkR+sfrWraQGG83xxac6lF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaseKan/aiday_training_resources/blob/main/TF_basics/Oplossingen_huiswerk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA-EvZMOuvSp",
        "outputId": "fddb0351-213d-4dc1-8c52-a9f77f49e2a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "print(tf.__version__)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrlqAU4ru70B"
      },
      "source": [
        "**Opdracht een & twee** Train een deep learning model op de Diabetes dataset (met maar een kolom) met maar een Dense laag met maar 1 neuron (unit). Train een lineair regressiemodel met sklearn. Maak daarna een scatterplot van de traindata met op de x-as de eerste kolom van de traindata en op de y-as de y_train. Voeg nu twee lijnen toe die met voorspelling van het sklearn model en het keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bMjyluu6jP"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# we houden voor deze opdracht enkel kolom drie\n",
        "x_train = x_train[:,2]\n",
        "x_test = x_test[:,2]\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(1,))\n",
        "dense = layers.Dense(1)\n",
        "output = dense(input)\n",
        "\n",
        "regressie_model = models.Model(input,output)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression().fit(x_train.reshape(-1,1),y_train)\n",
        "y_SK = lm.predict(x_train.reshape(-1,1))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4HxvAwZQw3pD",
        "outputId": "ad643688-7f4c-4379-8639-4263fab32b0b"
      },
      "source": [
        "# compilen model\n",
        "rate = 0.5\n",
        "rate_slow = 0.08\n",
        "epochs = 250\n",
        "def schedule(epoch, lr):\n",
        "  if epoch >= 50:\n",
        "    return rate_slow\n",
        "  return rate\n",
        " \n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
        "\n",
        "regressie_model.compile(optimizer=SGD(rate,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "# callback voor plot\n",
        "\n",
        "class Plot(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, batch, logs={}):\n",
        "    clear_output(wait=True)\n",
        "    y_DL = regressie_model.predict(x_train)\n",
        "    plt.scatter(x_train,y_train)\n",
        "    plt.plot(x_train,y_DL, label='keras')\n",
        "    plt.plot(x_train,y_SK, label='sklearn')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# trainen model\n",
        "history = regressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=x_train.shape[0],\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[scheduler,Plot()]\n",
        "                    )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUBvTRt7vUgs"
      },
      "source": [
        "**Opdracht drie** Gebruik nu alle diabetesdata en train een lineair regressiemodel. Train nu een deep learning model met betere validatie score. Vergelijke de MSE op de test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3U3SxHPvUtt",
        "outputId": "97219627-315b-4df0-9820-be17753d5e3c"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1)(dense1)\n",
        "\n",
        "regressie_model2 = models.Model(input,output)\n",
        "\n",
        "regressie_model2.compile(optimizer=SGD(5e-5,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "history2 = regressie_model2.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm2 = LinearRegression().fit(x_train,y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "8/8 [==============================] - 1s 35ms/step - loss: 31909.4095 - val_loss: 21607.6094\n",
            "Epoch 2/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 28816.4484 - val_loss: 13634.8486\n",
            "Epoch 3/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 16974.4474 - val_loss: 5957.7358\n",
            "Epoch 4/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8268.3120 - val_loss: 4516.5210\n",
            "Epoch 5/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6981.8676 - val_loss: 4329.1118\n",
            "Epoch 6/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6564.9880 - val_loss: 9642.0547\n",
            "Epoch 7/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7722.8877 - val_loss: 4496.3320\n",
            "Epoch 8/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5922.0016 - val_loss: 4348.9844\n",
            "Epoch 9/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5466.1571 - val_loss: 5699.9429\n",
            "Epoch 10/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5581.6830 - val_loss: 3643.4785\n",
            "Epoch 11/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4887.2243 - val_loss: 3598.7590\n",
            "Epoch 12/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4366.2906 - val_loss: 3814.3486\n",
            "Epoch 13/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3625.2437 - val_loss: 3406.5525\n",
            "Epoch 14/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3879.8238 - val_loss: 3266.1753\n",
            "Epoch 15/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3550.3943 - val_loss: 3279.2571\n",
            "Epoch 16/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3443.6044 - val_loss: 3648.7795\n",
            "Epoch 17/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3821.1285 - val_loss: 3852.8354\n",
            "Epoch 18/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3425.9451 - val_loss: 3281.2703\n",
            "Epoch 19/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3635.8960 - val_loss: 3520.1016\n",
            "Epoch 20/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3844.9336 - val_loss: 4352.4780\n",
            "Epoch 21/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3318.5920 - val_loss: 3759.9534\n",
            "Epoch 22/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3240.7402 - val_loss: 5073.4668\n",
            "Epoch 23/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4301.4643 - val_loss: 5112.4595\n",
            "Epoch 24/40\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4580.9862 - val_loss: 3498.4919\n",
            "Epoch 25/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3859.4266 - val_loss: 3391.4888\n",
            "Epoch 26/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4397.5155 - val_loss: 4462.9014\n",
            "Epoch 27/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3280.1688 - val_loss: 4313.7070\n",
            "Epoch 28/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4153.2046 - val_loss: 3482.0146\n",
            "Epoch 29/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3527.2791 - val_loss: 3537.8281\n",
            "Epoch 30/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4299.7663 - val_loss: 6788.4927\n",
            "Epoch 31/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4309.2496 - val_loss: 3190.3047\n",
            "Epoch 32/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3243.6446 - val_loss: 3335.5903\n",
            "Epoch 33/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3488.2632 - val_loss: 3852.9692\n",
            "Epoch 34/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2948.6512 - val_loss: 4151.0664\n",
            "Epoch 35/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3811.3772 - val_loss: 3364.5195\n",
            "Epoch 36/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3531.2945 - val_loss: 4033.9819\n",
            "Epoch 37/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3068.2747 - val_loss: 3438.4885\n",
            "Epoch 38/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3145.7921 - val_loss: 3339.1316\n",
            "Epoch 39/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2981.0897 - val_loss: 3406.0508\n",
            "Epoch 40/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2911.1594 - val_loss: 3577.5471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN9My7Zr_eO_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGku2miOwpW",
        "outputId": "919029c0-3eb0-46a5-c16a-84ad9449671f"
      },
      "source": [
        "print('Linear regression test MSE', np.mean((regressie_model2.predict(x_test)-y_test)**2))\n",
        "print('Deep Learning test MSE',np.mean((lm2.predict(x_test)-y_test)**2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear regression test MSE 8058.243063193635\n",
            "Deep Learning test MSE 2900.1732878832318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDGkcDYvU0D"
      },
      "source": [
        "**Opdracht vier** Ontwerp en train een meerlaags classificatiemodel op de breast cancer dataset. \n",
        "\n",
        "*   De activatie van je laatste laag moet voor binaire classificatie 'sigmoid' zijn (als er meer dan twee klassen waren geweest hadden we 'softmax' gebruikt)\n",
        "\n",
        "*   Als loss kan je 'binary_crossentropy' gebruiken\n",
        "\n",
        "Er zijn veel metrieken die je kan bekijken, bijvoorbeeld: precision, accuracy, recall, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAt2b6hfvU5p"
      },
      "source": [
        "# inladen data\n",
        "import pandas as pd\n",
        "data = pd.read_csv('telecom_churn.csv')\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.drop('Churn',axis=1),data['Churn'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1,activation='sigmoid')(dense1)\n",
        "\n",
        "logregressie_model = models.Model(input,output)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3F_B5SkRa77",
        "outputId": "eed7dfa3-f07d-4e11-f2d7-0db64c4b4efc"
      },
      "source": [
        "logregressie_model.compile(optimizer=SGD(5e-6,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Accuracy','Precision','Recall']\n",
        ")\n",
        "\n",
        "history2 = logregressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 74.3891 - accuracy: 0.0986 - precision: 0.1286 - recall: 0.8319 - val_loss: 6.5043 - val_accuracy: 0.0112 - val_precision: 0.0795 - val_recall: 0.0814\n",
            "Epoch 2/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 5.3349 - accuracy: 0.0087 - precision: 0.1510 - recall: 0.1709 - val_loss: 5.9010 - val_accuracy: 0.0037 - val_precision: 0.0723 - val_recall: 0.0698\n",
            "Epoch 3/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 4.8770 - accuracy: 0.0057 - precision: 0.1496 - recall: 0.1655 - val_loss: 5.2692 - val_accuracy: 0.0019 - val_precision: 0.0714 - val_recall: 0.0698\n",
            "Epoch 4/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 4.2543 - accuracy: 0.0063 - precision: 0.1534 - recall: 0.1663 - val_loss: 4.7497 - val_accuracy: 0.0000e+00 - val_precision: 0.0563 - val_recall: 0.0465\n",
            "Epoch 5/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 3.3350 - accuracy: 0.0030 - precision: 0.1535 - recall: 0.1619 - val_loss: 4.0859 - val_accuracy: 0.0000e+00 - val_precision: 0.0714 - val_recall: 0.0698\n",
            "Epoch 6/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 2.9816 - accuracy: 7.8277e-04 - precision: 0.1038 - recall: 0.1214 - val_loss: 3.5858 - val_accuracy: 0.0000e+00 - val_precision: 0.0563 - val_recall: 0.0465\n",
            "Epoch 7/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 2.8201 - accuracy: 3.1954e-04 - precision: 0.1318 - recall: 0.1359 - val_loss: 3.0470 - val_accuracy: 0.0000e+00 - val_precision: 0.0580 - val_recall: 0.0465\n",
            "Epoch 8/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 2.3398 - accuracy: 1.4359e-04 - precision: 0.1324 - recall: 0.1388 - val_loss: 2.4978 - val_accuracy: 0.0000e+00 - val_precision: 0.0875 - val_recall: 0.0814\n",
            "Epoch 9/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 1.9591 - accuracy: 3.0330e-04 - precision: 0.0754 - recall: 0.0883 - val_loss: 2.0812 - val_accuracy: 0.0000e+00 - val_precision: 0.1047 - val_recall: 0.1047\n",
            "Epoch 10/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 1.5479 - accuracy: 0.0000e+00 - precision: 0.1151 - recall: 0.1326 - val_loss: 1.7572 - val_accuracy: 0.0000e+00 - val_precision: 0.1026 - val_recall: 0.0930\n",
            "Epoch 11/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 1.3857 - accuracy: 0.0000e+00 - precision: 0.0853 - recall: 0.0927 - val_loss: 1.4906 - val_accuracy: 0.0000e+00 - val_precision: 0.0933 - val_recall: 0.0814\n",
            "Epoch 12/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 1.1452 - accuracy: 0.0000e+00 - precision: 0.0905 - recall: 0.0965 - val_loss: 1.2786 - val_accuracy: 0.0000e+00 - val_precision: 0.0816 - val_recall: 0.0930\n",
            "Epoch 13/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.0000e+00 - precision: 0.1186 - recall: 0.1359 - val_loss: 1.1188 - val_accuracy: 0.0000e+00 - val_precision: 0.0897 - val_recall: 0.0814\n",
            "Epoch 14/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.0000e+00 - precision: 0.0766 - recall: 0.0707 - val_loss: 0.9809 - val_accuracy: 0.0000e+00 - val_precision: 0.0909 - val_recall: 0.0814\n",
            "Epoch 15/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.8076 - accuracy: 0.0000e+00 - precision: 0.0793 - recall: 0.0676 - val_loss: 0.9358 - val_accuracy: 0.0000e+00 - val_precision: 0.0789 - val_recall: 0.0349\n",
            "Epoch 16/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.0000e+00 - precision: 0.0770 - recall: 0.0619 - val_loss: 0.8241 - val_accuracy: 0.0000e+00 - val_precision: 0.0732 - val_recall: 0.0349\n",
            "Epoch 17/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.0000e+00 - precision: 0.0973 - recall: 0.0672 - val_loss: 0.7373 - val_accuracy: 0.0000e+00 - val_precision: 0.0964 - val_recall: 0.0930\n",
            "Epoch 18/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.0000e+00 - precision: 0.1374 - recall: 0.1085 - val_loss: 0.7249 - val_accuracy: 0.0000e+00 - val_precision: 0.1053 - val_recall: 0.0233\n",
            "Epoch 19/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.0000e+00 - precision: 0.0609 - recall: 0.0289 - val_loss: 0.6344 - val_accuracy: 0.0000e+00 - val_precision: 0.0870 - val_recall: 0.0465\n",
            "Epoch 20/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.0000e+00 - precision: 0.0665 - recall: 0.0292 - val_loss: 0.6146 - val_accuracy: 0.0000e+00 - val_precision: 0.1094 - val_recall: 0.0814\n",
            "Epoch 21/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.0000e+00 - precision: 0.1184 - recall: 0.0518 - val_loss: 0.5808 - val_accuracy: 0.0000e+00 - val_precision: 0.0385 - val_recall: 0.0116\n",
            "Epoch 22/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.0000e+00 - precision: 0.1170 - recall: 0.0432 - val_loss: 0.5930 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.0000e+00 - precision: 0.1410 - recall: 0.0247 - val_loss: 0.5452 - val_accuracy: 0.0000e+00 - val_precision: 0.0909 - val_recall: 0.0116\n",
            "Epoch 24/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.0000e+00 - precision: 0.1866 - recall: 0.0331 - val_loss: 0.5351 - val_accuracy: 0.0000e+00 - val_precision: 0.1000 - val_recall: 0.0116\n",
            "Epoch 25/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.0000e+00 - precision: 0.1180 - recall: 0.0256 - val_loss: 0.5243 - val_accuracy: 0.0000e+00 - val_precision: 0.1250 - val_recall: 0.0116\n",
            "Epoch 26/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.0000e+00 - precision: 0.1996 - recall: 0.0246 - val_loss: 0.5196 - val_accuracy: 0.0000e+00 - val_precision: 0.2222 - val_recall: 0.0233\n",
            "Epoch 27/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.0000e+00 - precision: 0.4076 - recall: 0.0523 - val_loss: 0.5891 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.0000e+00 - precision: 0.2118 - recall: 0.0238 - val_loss: 0.5140 - val_accuracy: 0.0000e+00 - val_precision: 0.2500 - val_recall: 0.0116\n",
            "Epoch 29/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.0000e+00 - precision: 0.1655 - recall: 0.0275 - val_loss: 0.5085 - val_accuracy: 0.0000e+00 - val_precision: 0.2000 - val_recall: 0.0116\n",
            "Epoch 30/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.0000e+00 - precision: 0.1640 - recall: 0.0263 - val_loss: 0.5425 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.0000e+00 - precision: 0.1633 - recall: 0.0170 - val_loss: 0.5442 - val_accuracy: 0.0000e+00 - val_precision: 0.2742 - val_recall: 0.1977\n",
            "Epoch 32/40\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.0000e+00 - precision: 0.2159 - recall: 0.0683 - val_loss: 0.5080 - val_accuracy: 0.0000e+00 - val_precision: 0.3333 - val_recall: 0.0116\n",
            "Epoch 33/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.0000e+00 - precision: 0.1712 - recall: 0.0111 - val_loss: 0.5276 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.0000e+00 - precision: 0.0592 - recall: 0.0046 - val_loss: 0.5430 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.0000e+00 - precision: 0.3318 - recall: 0.0489 - val_loss: 0.5063 - val_accuracy: 0.0000e+00 - val_precision: 0.3333 - val_recall: 0.0116\n",
            "Epoch 36/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.0000e+00 - precision: 0.2360 - recall: 0.0254 - val_loss: 0.4965 - val_accuracy: 0.0000e+00 - val_precision: 0.5000 - val_recall: 0.0233\n",
            "Epoch 37/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.0000e+00 - precision: 0.1192 - recall: 0.0071 - val_loss: 0.4971 - val_accuracy: 0.0000e+00 - val_precision: 0.5000 - val_recall: 0.0233\n",
            "Epoch 38/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.0000e+00 - precision: 0.5628 - recall: 0.0386 - val_loss: 0.5147 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.0000e+00 - precision: 0.1633 - recall: 0.0189 - val_loss: 0.4955 - val_accuracy: 0.0000e+00 - val_precision: 0.5000 - val_recall: 0.0233\n",
            "Epoch 40/40\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.0000e+00 - precision: 0.1048 - recall: 0.0079 - val_loss: 0.5155 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahpahNKrQn-k",
        "outputId": "e004d73d-82e4-4aed-bea0-daff4dba5f99"
      },
      "source": [
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogReg = LogisticRegression().fit(x_train,y_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxHUxcP9SCLX",
        "outputId": "b777052f-bc21-4482-a9a0-0071d304f97d"
      },
      "source": [
        "acc_DL = (np.array(tf.greater(logregressie_model.predict(x_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of deep learning model is',acc_DL)\n",
        "acc_SK = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_SK)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of deep learning model is 84.8575712143928\n",
            "Accuracy of Logistic Regression model is 84.70764617691154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvQQR6nvU_y"
      },
      "source": [
        "**Bonus: ensembling/stacking** Laten we kijken of we met stacking het bovenstaande deep learning model kunnen verslaan. Bij ensemblen trainen we in dit geval een netwerk met maar een laag, die de optimale combinatie van voorspelling zoekt van andere modellen. Doorloop de volgende 3 stappen:\n",
        "1. Train drie verschillende classificatiemodellen met sklearn, bijvoorbeeld randomforest, logistic regression en KNN\n",
        "2. Maak een nieuw numpy array met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_train. \n",
        "3. Gebruik dit nieuwe dataframe als input voor een eenlaags neuraal netwerk met 1 neuron (zoals we bij opdracht een hadden ontworpen). De labels blijven natuurlijk y_train. \n",
        "\n",
        "Gefeliciteerd je hebt nu een ensemble model getraind! Om te testen of dit model beter werkt dan je deep learning model moet je nog 2 stappen doorlopen.\n",
        "\n",
        "i. Maak een nieuw dataframe met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_test.\n",
        "\n",
        "ii. Doe model.predict op deze nieuwe dataset en bereken handmatig de loss en metrieken. \n",
        "\n",
        "*Nota bene: je kan de resultaten nog verder verbeteren door 4 modellen te ensemblen, waarvan het vierde model je deep learning model uit opdracht 3 is*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIca6LiuvVGS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "RF = RandomForestClassifier().fit(x_train,y_train)\n",
        "KNN = KNeighborsClassifier(n_neighbors=3).fit(x_train,y_train)\n",
        "\n",
        "ensemble_train = np.transpose(np.array([LogReg.predict(x_train),RF.predict(x_train),KNN.predict(x_train)]))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3AOEB2UxCA",
        "outputId": "8653293b-5d96-412c-afe4-4a9057ec7d41"
      },
      "source": [
        "ensembler = models.Sequential()\n",
        "ensembler.add(layers.Input(shape=(3)))\n",
        "ensembler.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ensembler.compile(optimizer=SGD(1e-2,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Accuracy','Precision','Recall']\n",
        ")\n",
        "                  \n",
        "ensembler_history = ensembler.fit(x=ensemble_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=100,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "54/54 [==============================] - 1s 9ms/step - loss: 0.6432 - accuracy: 0.0000e+00 - precision: 0.9818 - recall: 0.5045 - val_loss: 0.5314 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4487 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3983 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3624 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3338 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3095 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2885 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2691 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2522 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2370 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.0000e+00 - precision: 0.8909 - recall: 0.0612 - val_loss: 0.2230 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 0.5116\n",
            "Epoch 12/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.4563 - val_loss: 0.2106 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 0.5116\n",
            "Epoch 13/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 0.5412 - val_loss: 0.1991 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 20/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 21/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 22/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 23/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 24/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 25/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 26/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 27/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 28/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 29/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 30/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 31/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 32/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 33/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 34/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 35/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 36/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 37/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 38/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 39/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 40/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 41/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 42/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 43/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 44/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 45/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 46/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 47/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 48/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 49/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 50/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 51/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 52/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 53/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 54/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 55/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 56/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 57/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 58/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 59/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 60/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 61/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 62/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 63/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 64/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 65/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 66/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 67/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 68/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 69/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 70/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 71/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 72/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 73/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 74/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 75/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 76/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 77/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 78/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 79/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 80/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 81/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 82/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 83/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 84/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 85/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 86/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 87/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 88/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 89/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 90/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 91/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 92/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 93/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 94/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 95/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 96/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 97/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 98/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 99/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 100/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjpfrg8WNTW",
        "outputId": "18289ceb-0a3e-4c5b-b021-29cd4e4137e4"
      },
      "source": [
        "ensembler_test = np.transpose(np.array([LogReg.predict(x_test),RF.predict(x_test),KNN.predict(x_test)]))\n",
        "acc_DL = (np.array(tf.greater(ensembler.predict(ensembler_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of ensembler model is',acc_DL)\n",
        "acc_LR = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_LR)\n",
        "acc_KNN = (KNN.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of K-nearest neighbors model is',acc_KNN)\n",
        "acc_RF = (RF.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Random Forest model is',acc_RF)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of ensembler model is 92.65367316341829\n",
            "Accuracy of Logistic Regression model is 84.70764617691154\n",
            "Accuracy of K-nearest neighbors model is 85.00749625187406\n",
            "Accuracy of Random Forest model is 92.65367316341829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4qKzEotDf_9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}