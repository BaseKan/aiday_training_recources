{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oplossingen_huiswerk.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO78V7Mf/sqTK/augZixbjZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaseKan/aiday_training_resources/blob/main/TF_basics/Oplossingen_huiswerk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA-EvZMOuvSp",
        "outputId": "162b7e33-39a0-4369-81b7-c07b9a449ec0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "print(tf.__version__)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrlqAU4ru70B"
      },
      "source": [
        "**Opdracht een & twee** Train een deep learning model op de Diabetes dataset (met maar een kolom) met maar een Dense laag met maar 1 neuron (unit). Train een lineair regressiemodel met sklearn. Maak daarna een scatterplot van de traindata met op de x-as de eerste kolom van de traindata en op de y-as de y_train. Voeg nu twee lijnen toe die met voorspelling van het sklearn model en het keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bMjyluu6jP"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# we houden voor deze opdracht enkel kolom drie\n",
        "x_train = x_train[:,2]\n",
        "x_test = x_test[:,2]\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(1,))\n",
        "dense = layers.Dense(1)\n",
        "output = dense(input)\n",
        "\n",
        "regressie_model = models.Model(input,output)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression().fit(x_train.reshape(-1,1),y_train)\n",
        "y_SK = lm.predict(x_train.reshape(-1,1))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4HxvAwZQw3pD",
        "outputId": "ac9c9ef3-47b6-4379-bc94-964dad623ef0"
      },
      "source": [
        "# compilen model\n",
        "rate = 0.5\n",
        "rate_slow = 0.08\n",
        "epochs = 250\n",
        "def schedule(epoch, lr):\n",
        "  if epoch >= 50:\n",
        "    return rate_slow\n",
        "  return rate\n",
        " \n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
        "\n",
        "regressie_model.compile(optimizer=SGD(rate,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "# callback voor plot\n",
        "\n",
        "class Plot(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, batch, logs={}):\n",
        "    clear_output(wait=True)\n",
        "    y_DL = regressie_model.predict(x_train)\n",
        "    plt.scatter(x_train,y_train)\n",
        "    plt.plot(x_train,y_DL, label='keras')\n",
        "    plt.plot(x_train,y_SK, label='sklearn')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# trainen model\n",
        "history = regressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=x_train.shape[0],\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[scheduler,Plot()]\n",
        "                    )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3zURfrH35PNhiSghKZCAAFFsCAgCCg2sKCigoCCoGI79dRTOX8gtgPbgXLqwVk4OHsFRCOCggWsCEhHEESlRlBEEoS0TTK/P7Zkd/Otu9+tmffrxYvs7LfMfHf3M88888wzQkqJQqFQKNKLjERXQKFQKBTOo8RdoVAo0hAl7gqFQpGGKHFXKBSKNESJu0KhUKQhmYmuAEDTpk1lmzZtEl0NhUKhSClWrFjxu5SymdZ7SSHubdq0Yfny5YmuhkKhUKQUQohteu8pt4xCoVCkIUrcFQqFIg1R4q5QKBRpiKnPXQiRDXwB1PMd/7aUcpwQ4iXgTKDYd+g1UsrVQggBTAYuBEp85SvtVszj8bBz507KysrsnlonyM7OpmXLlrjd7kRXRaFQJCFWJlTLgb5SygNCCDfwlRDiQ997o6WUb4cdfwHQ3vevJ/Cc739b7Ny5k0MOOYQ2bdrg7S8UfqSU7N27l507d9K2bdtEV0ehUCQhpuIuvZnFDvheun3/jLKNDQBe8Z23RAiRJ4RoLqXcZadiZWVlSth1EELQpEkT9uzZk+iqKBSKCClYVcikBZv4paiUFnk5jO7XgYFd8x27viWfuxDCJYRYDfwGfCylXOp761EhxFohxFNCiHq+snxgR9DpO31l4de8UQixXAixXE+klLDro56NQpG6FKwq5J531lFYVIoECotKueeddRSsKnTsHpbEXUpZJaXsArQEegghTgDuAToCJwONgbvt3FhKOU1K2V1K2b1ZM80YfIVCoUhLJi3YRKmnKqSs1FPFpAWbHLuHrWgZKWURsAg4X0q5S3opB14EevgOKwRaBZ3W0leWcmzdupUTTjgh0dVQKBQWKFhVSO+JC2k7dh69Jy501Ap2ml+KSm2VR4KpuAshmgkh8nx/5wDnAhuFEM19ZQIYCHznO2UOcLXw0gsotutvT3UqKysTXQWFok4RDzeHk7TIy7FVHglWLPfmwCIhxFrgW7w+97nA60KIdcA6oCnwiO/4D4CfgR+B6cAtjtU2gfz888907dqVpUuXcv7559OtWzdOP/10Nm7cCMA111zDzTffTM+ePRkzZgzLli3jlFNOoWvXrpx66qls2uQdbq1fv54ePXrQpUsXTjzxRDZv3pzIZikUaUE83BxOMrpfB3LcrpCyHLeL0f06OHYPK9Eya4GuGuV9dY6XwK3RV62GB99fz4Zf9jt5SY5rcSjjLj7e0rGbNm1i2LBhvPTSS/z9739n6tSptG/fnqVLl3LLLbewcOFCwBu+uXjxYlwuF/v37+fLL78kMzOTTz75hHvvvZfZs2czdepU7rjjDkaMGEFFRQVVVVUmd1co0p9oI0fi4eZwEn/bYhktkxSJw5KZPXv2MGDAAN555x1at27N4sWLueyyywLvl5eXB/6+7LLLcLm8vXFxcTEjR45k8+bNCCHweDwAnHLKKTz66KPs3LmTQYMG0b59+/g2SKFIMvwuFb/l7XepAJbFrkVeDoUaQu6km8NpBnbNd1TMw0kJcbdqYceChg0b0rp1a7766iuGDRtGXl4eq1ev1jy2fv36gb8feOAB+vTpw7vvvsvWrVs566yzABg+fDg9e/Zk3rx5XHjhhfz3v/+lb1/NQZBCUScwcqlYFb/R/TqEdBDgvJsj1UgJcU8kWVlZvPvuu/Tr148GDRrQtm1bZs2axWWXXYaUkrVr19K5c+da5xUXF5Of7/1ivvTSS4Hyn3/+mXbt2nH77bezfft21q5dq8RdETNivVDGCZxwqcTDzZFqKHG3QP369Zk7dy7nnnsuV155Jc8//zyPPPIIHo+HYcOGaYr7mDFjGDlyJI888gj9+/cPlM+cOZNXX30Vt9vNEUccwb333hvPpijqEE64O+KBUy6VWLs5Ug3hnf9MLN27d5fhm3V8//33HHvssQmqUWqgnpHCiN4TF2qKZn5eDl+PTZ7RYngnBF6XyoRBnZRYmyCEWCGl7K71nrLcFYo0JVUiSJRLJTYocVco0pRUiiBRLhXnUZt1KBRpSjwWyiiSF2W5KxRpinJ31G2UuCsUaUwyuTtSISwznVDirlAoYk6qhGWmE8rnbpM2bdrw+++/1ypv0KBBAmqjSEZSKfVsvEi1xF7pgLLck4yqqqpAfhpF6qEsVG1SJSwznVCWuwEHDx6kf//+dO7cmRNOOIEZM2YE3istLeWCCy5g+vTptc6bNGkSJ598MieeeCLjxo0LlA8cOJBu3bpx/PHHM23atEB5gwYNuOuuu+jcuTPffPMNDRo04L777qNz58706tWLX3/9NbYNVTiGslC1iUf+ckUoqWG5fzgWdq9z9ppHdIILJhoeMn/+fFq0aMG8efMAb76Yu+++mwMHDjBs2DCuvvpqrr766pBzPvroIzZv3syyZcuQUnLJJZfwxRdfcMYZZ/DCCy/QuHFjSktLOfnkkxk8eDBNmjTh4MGD9OzZkyeeeALwdiq9evXi0UcfZcyYMUyfPp3777/f2fYrYoKyULVRib3iT2qIe4Lo1KkTd911F3fffTcXXXQRp59+OgADBgxgzJgxjBgxotY5H330ER999BFdu3pT4B84cIDNmzdzxhlnMGXKFN59910AduzYwebNm2nSpAkul4vBgwcHrpGVlcVFF10EQLdu3fj4449j3dSEky6RFHYXDiVzu52smwrLjD+pIe4mFnasOOaYY1i5ciUffPAB999/P2effTYAvXv3Zv78+QwfPhzvLoM1SCm55557uOmmm0LKP/vsMz755BO++eYbcnNzOeussygrKwMgOzs7xM/udrsD13W5XGm/bV86+antWKjJ3O5Y1C2ZwjITTsVBePEC2LUGLn8Fjhvg+C2Uz92AX375hdzcXK688kpGjx7NypUrAXjooYdo1KgRt95ae8Opfv368cILL3DgwAEACgsL+e233yguLqZRo0bk5uayceNGlixZEte2JDPp5Kce2DWfCYM6kZ+Xg8CbpEsvAVYytzuZ62aFpI1YqiiB6WfDP1t4hR3gsNjsV5EalnuCWLduHaNHjyYjIwO3281zzz3HkCFDAJg8eTLXXXcdY8aM4fHHHw+cc9555/H9999zyimnAN7J0tdee43zzz+fqVOncuyxx9KhQwd69eqVkDYlI+nmp7ZqoSZbu4PdMHq5YlPhM0nKEZGnDF69FLYvrinrdSv0exTCRv9OoVL+pjDp8oxSJTWt0yRTu7XS7mqRCp9JMj1XKsvh9SGw5Yuash43wgWPOyLqRil/lVtGkXDineAqWYbso/t1wO0K/YG7XSIhESRabphwUiW6JSlGRJUV8OogeOSwGmHvdg38Yx9cOClm1nowpm4ZIUQ28AVQz3f821LKcUKItsBbQBNgBXCVlLJCCFEPeAXoBuwFhkopt8ao/oo0IJ6RFEk3ZA8fOCdoIG0kfAJSKroloamOqzww40r4YX5NWZcr4ZL/QEZ8bWkrPvdyoK+U8oAQwg18JYT4EPg78JSU8i0hxFTgeuA53//7pJRHCyGGAY8BQyOpnJSyVjSKwksyuNOcJF6RFE5sxuxkXTzVoZ+jp1ompC56gpgKbphwEhJTX1UJb18D379fU3biUBj4HGQkZsW5aVcivRzwvXT7/kmgL/C2r/xlYKDv7wG+1/jeP1tEoNDZ2dns3bs37UTMCaSU7N27l+zs7ERXJeVIiiG7yT0TUZd0yv1uJ2Ipaqqr4O3r4OEmNcJ+/KXwwF4YNC1hwg4Wo2WEEC68rpejgWeAn4AiKaU/AHsn4H9y+cAOACllpRCiGK/rpna2LQNatmzJzp072bNnj53T6gzZ2dm0bNky0dVIOfQs1AwhaDt2XlzdD8m0U1K6LTKK+UiwugoK/gpra1KScOzFMOQlcCVHEKKlWkgpq4AuQog84F2gY7Q3FkLcCNwI0Lp161rvu91u2rZtG+1tFIoQtIbsAFW+EWI8ffDJtiRfLTKyQHU1vP83WPVaTdkx58PQ18DlTly9NLDVxUgpi4QQi4BTgDwhRKbPem8J+EMOCoFWwE4hRCbQEO/Eavi1pgHTwBsKGXkTFPEk0iXpybLMPtxCzRAiIOx+Yu2DD34Weblu6mVmUFzqSXlrOa2REuaOghUv1pQd1ReueAsy6yWuXgZYiZZpBnh8wp4DnIt3knQRMARvxMxI4D3fKXN8r7/xvb9QKsd5WhBppEmyRagEW6htx87TPCZWfu/wZ7GvxEOO28VTQ7soUU9GpIQPx8CymiyutDkdRrwN7ujmvCqrqlmw/ldOa9+UhjnOW/1WYnOaA4uEEGuBb4GPpZRzgbuBvwshfsTrU3/ed/zzQBNf+d+BsY7XWpEQIl2SnsxL2eOdijaZn4UiCClhwX3wYF6NsLc+Be7bDdfMjUrY9x4o57ynPufo+z7k1jdWsmD9bocqHYqp5S6lXAt01Sj/GeihUV4GXOZI7RRJRaTRHckUFRJOvP3esXgWyeLySgukhE/GwdeTa8ryu8HIuZCVG9Wl1+0s5uKnvwop63f84Vwao88qOaZ1FSlBpNEdyRQVEk68o0ScfhbJ5vJKaRY+Cl/U5IniiBPh2g+hXnRbaL69Yif/N2tNSNnYCzpy0xntYrqOR4m7wjKRWrnJFhUSTjyjRJx+Fsm0KCtl+fxxWPRozevDjoPrFkD2oRFfsqpaMm7Od7y2ZHtI+avX9+D09s0ivq4dlLgrLGNm5eq5B5IlhjoZ3BdOP4tkdnklPV8+AZ8+VPO6ydHwl4WQ3TDiS+47WMGVzy9l/S/7ay5bP4uCW3vTqnF0bh27JG1WSEVqoZVVMMftit3KQIN6aAlnstTPKlY7oqTKgJggbHfai/8DHwVtW5l3JNz0OeQ0irgO638ppv+UUH/6Occexn+uOImcrNitUjXKCqksd4UjJIN7wMj/nKj6RTJasONHT3aXV6yxNeewZCrMv7vm9aH5cPNXkNs44vu/u2ono2aE+tNH9+vALWcdlfC8WErcFY6QDO4BIwFPRP0iney00xHF0uWVDG4sMyw9q2XT4YP/qzmgfjO4ZQnUbxrRPauqJQ++v55XvtkWUv7StSdzVofDIrpmLFDirnAEJ6JAtMQErAuXkYAnImIn0tGC1Y4o/Hk5uRAqVaJwDJ/Vipfg/TtqCrMbwq3fwiGHR3SvopIKrnp+GesKiwNlDXPcvH/babRuEl9/uhWUuCscIVr3gJaYjJ61BgR4qqzlfTES8ES4LyIdLVjpiIzEF+DB99ezr8QDQF6Om/GXHG9LlO10TIm08LWe1RDX5/zL/V/wZ9/NagC3LYdDm0d0jw2/7OfCKV+GlJ3VoRnPjjiJ3KzkldDkrZkipYjWPaAlJuG5zsFYYEoqKmsd7xfwRETsRDpasNIR6Ynv+DnrOVhRGegQAYpKPd6OEutWt9WO6f6Cdby+ZHtgj5F4W/jBz2pgxlf8O+vZmjddWXD7amgYWT3eW13IHW+tDikbdc4x3H720Qn3p1tBibvCMaKJF7fj+9ZyT2hlegy3WOOd9dCKSBtZvUYdkd7zKir1aJbb3QTE6ughWNj9xHMifWDXfPILP+Tk5XcFyiQCcedayKudbdaM6mrJw/M28OLXW0PKX7imO307RubOSRRK3BVJgZ6Y6B0bjN7+n/XrZdoWGCddDFbWBRj5tY3ua+d5+bHTgVodPegFUmvdy3H3zYb3YObVnBxcdscaRKM2ti9VXOph5AvLWL2jKFDWoF4m7//tNNo2rR95HROIEndFUqAlJu4MEeJzh1CB8YuFnsjZjYSJxSSikUjruVbunLGaSQs2GYqfnvhmuzMCvvZw7EweRzN60LqXo8924zx4a3ho2d9WQpOj7F0H2LT7T/r9+4uQstPbN2Xqld2oXy+15TG1a69IG/TERKtMb1FSOHYjYeIdC28kjmbiZ/S8Rr+9JqRDBG9HaXfyONLRg4Ba93Lk2f7wEbwRlpPwtuXQtL2184OYt3YXt76xMqTs9r5HM+rcY1LCn24FJe6KpEFPTLTK9FwxftwuQZ+Ozejy4EcBP3SjXDfjLtaPGol3LLyZa8VM/IzEN9poGStojR4EMKJX61r3iurZ/vgpvDYotOyWpXCYvQ3hqqslE+dvZNoXP4eUT7+6O+cel1r+dCsocVekJGaiUFUleWPpdoIDbvaVeBj9tn7USLxj4fW2/Asmko4l1hPHwb7zhjlust0ZFJUY7yQV0bP9+TN4ZUBo2V8Xw+HH26rv/jIP1734Lcu37QuUZbszmHf76RzVLLqMj8mMEneFY8Qz3tnM6q0GtGb7PFX6USPxjoUPdq3otSUZ0iIHE+4OKyq1tpOUrWe79St4qX9o2U1fQvMTbdV1869/cv7kL6kK6uFPadeE6SO70yDF/elWSP8WKuJCvFc0WrF69dCzhhMRC++3svUSm8UzR4yVzjlS37mlZ7t9CbzQL/TEGz+DFrX2CjJk/ne7uPm1UH/6LWcdxeh+HdLGn24FJe4KR7Dyo49VmKHdkEAja9gJl0Yk7bTbsTg9SrLaOUfjO9d7tp9/+gFnfnlFaOENn0JLzWSHmkgpeWz+JqZ+/lNIeePcLPaVVPDe6l845vBDkip1QqxR4q6ImGCBMYt3jmWYYcGqQu6csdr8BLwTrbG0hqNpp9WOJZp76HUKVi1yR+clClfC9D6cGVQ0qHw832cey4Q9zRnY0vwSf5Z5uOHl5Szd8kegzO0S3HVeByZ/spk/Siq8t0rS3DixxMoG2QpFLfwCU2gg7FDzo4/lxtADu+aTp7N7fPAgvFGum0lDOsf0xx2PDbAjvUf4Z+YXvIJVhZYt8tH9OpDjDs1Pbtt9tGsNjG8I0/sEii4vf4A2ZW+wUh5jqS0/7TnAMfd/SKfxHwWEvUebxqwdfx6bH72QV7/ZVuc3IleWuyIizEIRIfRHH+sww/GXHJ8Um3HEI5wy0nsYdQpWLfKo5iV2fwdTe4cUDa+4j8XVtaNf9Nry0frd3PjqipCym85ox93ndyQjo6YrT4YU1IlGiXuKEa2v1SlfrdGPRECta8c6zDBZtvKLRzil3j0yhKDt2Hm6bTcSvKeGdrE8oWt7XuK37+HZXqFlV70LR/Vl28SFYPK8pJQ88dEPPL3ox5Bjnhl+Ev1P1M70mMybsscLU3EXQrQCXgEOxxtcNk1KOVkIMR74C7DHd+i9UsoPfOfcA1wPVAG3SykXxKDudY5o/dZO+r31fjx627vFI8ww3onBtIhHO/UihaqkcWpkI8GLSee45wd45uTQsuGz4JjzDNvif14Hyyu58dXlfP3j3sB7QsD8O86gwxGHGN66ru9QBRb2UBVCNAeaSylXCiEOAVYAA4HLgQNSyn+FHX8c8CbQA2gBfAIcI6XUHcOrPVStEe1+mU7utxnJnqRGo4ZU2PXHKvFoS/A9MoQICHsw4Z9r3PaR3fsT/Oek0LIr3oIOF2geHv68rjm1DU998gMlFTX1PKl1Hi9e24OGOnMrVq6byt8pPYz2ULW9QbYQ4j3gaaA32uJ+D4CUcoLv9QJgvJTyG71rKnG3Rtux8zQnLwWwZWJ/jXecPT+c8JWKQmC6UlHvOsngL9eqVyqIg53PNaZt+mMLTOkSWnb5q3DcJZZO//T7X7n+5VAduP60ttx34bEh/nRFDY5tkC2EaAN0BZbiFffbhBBXA8uBu6SU+4B8YEnQaTt9ZeHXuhG4EaB1a/t5l+si0foRnfZD6i3AseLuMbM8I03Y5ZR4ae4M9fYaxs9ZT3Gp/Q7M7r3ttMHO5xoT19W+bTA5bPXokBfhhEHaxwchpeTfn2xm8qebQ8qnXNGVSzq3cLKWdQ7LoZBCiAbAbOBOKeV+4DngKKALsAt4ws6NpZTTpJTdpZTdmzVrZufUOku0YWiOhLFpYDc0LzwkT8ulAJGn7NUK9TM6p/fEhbQdO4/eExcGjtXcGapKUlTqsXztSIikDbH6XE0p3gkPNQkV9kHTYXyxqbCXVFRy9QvLaHvPByHC/uEdp7N1Yn8l7A5gyXIXQrjxCvvrUsp3AKSUvwa9Px2Y63tZCLQKOr2lr0wRJdFOesUqosRu2JmVMEowHlFoWbd2l8YbjTisdCyxSAdstH2eUXZI/7lxcSHt3wVTukJl0DMa+BwF8kwmfbCJX97Qj9jZtvcgF/3nK/4sq9kSsXPLhrx8XQ/ycrNiU986ipVoGQE8D3wvpXwyqLy5lHKX7+WlwHe+v+cAbwghnsQ7odoeWOZoresw0Q6r9c6Pxp1h191jRTiNLE89UdbrMOx0MmZx31avHSl69ywq9VCwqjCi9L+O8eev8HR3KN9fU3bxFOg20tQ1t2jTb1z74rchl7vm1DY8cNFxuJQ/PSZYsdx7A1cB64QQ/jXe9wJXCCG64A2P3ArcBCClXC+EmAlsACqBW40iZRSJJ9oQSbthZ3rC6RKCailNOxc9UXbpRI3Y7WT04r712uIkem0A4rYvaS0O7IFne0JJTUgi/Z+Ak28IqZvWZ/LAe9/VSg3xb5MMkgpnMBV3KeVXhK7i9vOBwTmPAo9GUS9FHIl2lxy7bgG9zsBqdIyeKFdJSY7bFXUnoxX3nZfr5kBZJZ5q7S3/nEJP2CEBqysP7oXnToUDu2vKzn8Met1c61C9ugW7X+bdfhrHt2ho6dapEqmUzKgVqgpHlmrbcQtE6yM2WkDl971H08n06diM3hMXBq7hz1UeD8HJN3AHxW11Zckf8N8zoHhHTdl5j8Kpt+meoveZuF2CZfeeQ6P61v3p8U4fna4ocVckZKm2lc4gWEzzct1I6d2lPi/XjTtDaFrR0XYyfTo2Y/aKQl1hibW4jO7XwbE9UG1TWuRN5vVH0DZ054yH00YZnvbFD3s0vz/ZmRlMHHyiLWGH+O9lm64ocVck5VLtcOvNvx+o/2+3S5CX44465jxcsHtPXBiRsDhl1fvPicceqAHK9sP/zoHfg0JX+9wPZ47WPUVKyXOf/8Tj80PDXfNy3RRHsJAtmEQk/UpHN5ASd0XSJN0Kxixc0lMlqV8vk9XjztM9JhIiERan3Qhxy5FTfsC789Gv39WUnXk39LlX95QyTxV/e3MVH2/4NaT8/dtOo1NLa/50M+I9kkxXN5ASdwXgrKCYWUFWrCQrVlosLLlIhCXl3AgVB717lP6yqqbstFFw9jhvZi4Ndu4rYeAzi/n9QHmgrOMRh/D6DT1p0qCeo9WL90gy5T4/iyhxVziKmRVk1UqyEmceC0suEmFJmdzhnlJ4+RLYGbTs5JTb4LxHdEV98Y+/M/x/S0PKrujRiocHnECmKzZ7/cR7JJkyn59NlLgrHMXMCrJqJZltgB0rSy4SYUn63OGeMnhtEGz7uqas581w/kRNUZdSMv3Ln/nnBxtDyh8ffCKXn9yq1vGxIJ7pm5P+84sQJe4KRzGzgqxaSVpx5v5oGb/gAiEhi1asOysuIbvCkowT0gBUlsPrl8GWz2vKul/vXYCkIeplnipGzVjNh9/tDil/79bedG6VF+vaJoyk/fyiRIm7wlHMrCCnMhhGmokyFhNnSTchXVkBbw2HHz+uKTvparhoMmTUdqX8UlTKoGcXs3t/WaCs/WENePPGXjR12J+ejCTd5+cQtvO5xwKVzz19MMvN7lTu9kg2HnFysxKrxDXErsoDM6+GTUGLxztfAQOe1RT1JT/vZdi0JSFll3dvyaOXdsIdI3+6wlkcy+euSH+iFSMzKyhaK8lfP73JVqNJsHhPnMU6xM7/LH4tOsBz2c9wbtA2Cjvy+9Pq+lchw1XrvOe/2sLDczeElP3z0k4M76n2VUgnlLgrAjglRmY+60gny7Ss/nCMJsHiPXEWyxC7glWF3PfOGv7JfxiQvThQPq+qB7d7/kbW9iwmrNkduE95ZRV3zVzD3LW7Qq7zzi2nclLrRlHVRZGcKHFXBDDbdMOute20S8JsYZPZJFi8J86cGinUeo7ntafe3NtY7/oscMzHVd34q+cOKn0/af/n1qtdEwY/tzikU2vXtD5v3dSLww7Jtt8oRcqgxF0RQE90wvOlJ2ry0kgU8y10HvGeOIt0pBC+N+3Biko8VRJBNbcdmMLAOYsCx35W1Zm/eO7Co/FTLiwqpdeETwOvB52Uz2ODT1T+9DqCEvc0IlpL2SjPul33QixcEkbZIK1OiMYzfjqSkUJ4p1hU6gEkj2S+wJWZNUL9dfUJXFsxmgrcpvV4eOAJXNXryMgbokhJVBeeJkSy92Y4fTpq72UbyR6nsZi81NorVOBta/D+p8nCwK75TBjUify8HATeTsgsKii0U5SMy3yZrdkjAsK+tLojHcpeYkTFvbjcxm6V2/sezdaJ/ZWw11GU5Z4mOGEpL9q4R7Pc7g5H/veinbzUGolMGNQpEC0j8G4DBsmb7MnuSMHb+UnuzXyDGzPnBcpXVLdnRMW9lOGNO8/Py+HGM9rx0NwNVFWHfjZHHJrN2As6JtVzUMQfJe5pgpGlbNVd49QORxD95KWez37CoE58PbavZsx6tG6fhKd9lZKH6r/NVVXvBIrWVrdlaMUDlFJjpWe5MigsKmXcnPWBsgFdWjBpSGeyMtVgXOFFiXuKoSdAepZyXq7b8sSm1R2O/KkARs1YzaQFm3SX8EPkk5dmIxGn3T4JT/u66J/w+WNc5Xv5fXVrhlSM4yA5uDMEjbIzA/ndK6qqA6eNu/g4ru3dNvb1U6QcStxTCCMB0rOUpcSyu8bI2va7F+yIYDSTl2bi7XTMesLSvn4+CRY9UvO66THM7fEqExb+QklFKS0aZpPfKIdvt+4LOW3Gjb3o2a5J7OqlSHnUGC6FMBMgrcm74lKP5rW0xNPKBKBZLLxT6Im0v1xrcjWamPW4p3396ikY37BG2Bu1hbu3wW3fclGPjhTc2pu2zerzS3FZQNjz83L45p6+bJ3YXwm7whRluacQZgKkZSnrLdXXE08zazteImjms3cqZt3v5tLLsGR1JGDZX9NHtSAAACAASURBVP/NM7AgaKejhq3gpi8gtzEAq7bv49JnF4ec0v/E5jx5eWfqZdZOJaBQ6GEq7kKIVsArwOF4gxOmSSknCyEaAzOANsBW4HIp5T4hhAAmAxcCJcA1UsqVsal++mBFHCJxRWiJpDtDUFJRSdux82yLYiyW8Bu1Xa/ciclPs3QGVkcCllxVS/8LH46pOanBEfDXxVDfa4G/uWx74Bw/9/c/lhtOb2erTbEm4ZPOCstYsdwrgbuklCuFEIcAK4QQHwPXAJ9KKScKIcYCY4G7gQuA9r5/PYHnfP8rdLDqx44kAiVcJHPcGZR4qgOTc3YnDvt0bMZrS7Zrloe3yYoImLU9knOsYpbOINut7bUMb1tJRaW+u6xyPsz7e80bOY3h1mXQoBmVVdXc9/ZaZizfEXLum3/pxSlHJZ/bJeGTzgpbmIq7lHIXsMv3959CiO+BfGAAcJbvsJeBz/CK+wDgFenNJbxECJEnhGjuu45CA6uTeZG6IoInQ0fNWF3rfTsTh3qx8G8u3UH3IxvbnnSNZCLTqRw4Zq6kfSWeWvXWapsWl7sW8XjZdPCHqtc7FG77Fg45gr0Hyrniqc/54dcDgeOPODSbd245Nal3/0nXvUbTFVs+dyFEG6ArsBQ4PEiwd+N124BX+INNkZ2+shBxF0LcCNwI0Lp13U41asePHU0EipFv2arP3CgW3i+EZiIQbPlGUp9Ic+CEW9x5ue7ACEaPcPEys/YHZXzBk1lTawoyc+D2lXBoC9bsKGLAo/NCjr/ghCN4amgXst3J709P171G0xXL4i6EaADMBu6UUu4XQdt0SSmlEMLWrh9SymnANPBu1mHn3HQjXqlojX6EVu9ltHG1XwjNFlSZpe01q08kOXCAWsLvzhC4XQJPlfHXL7g9em27JONrpmQ9E3hdKTP4tN/H9Du1OzO/3cGY2aGifu+FHfnL6e0QOhtTJyPputdoumIpFFII4cYr7K9LKf3L534VQjT3vd8c+M1XXggE76Lb0lem0MHpsD499H6EwlcHK2jVNRi/Vax3fzPLF6ytftV6XkY5cLTu66mW1M/KDIR+unSENrg94W3rn7GErdnDQ4T9jPIpvHfJOj7bXY82Y+cxZvbawHuv39CTfw/twsuLt9Hung+SMieOHvH6niqcwVTcfdEvzwPfSymfDHprDjDS9/dI4L2g8quFl15AsfK3GxNJgqlgClYV0nviQtqOnWcoFnqJt0b0am35Xv66GgmhkQiYDeFdQjC4m/HeqX6h9tfB/7zyDToVvfsWl3r4emxftkzszxOXdzYVL3/b+mV8y9bs4TyTNSXw3hnlT9Gm7A22y6bcNWsNby7zTjw3bZDFl2P6sHVif/b8WR51grdEEe33VBFfrLhlegNXAeuEEP7ZuHuBicBMIcT1wDbgct97H+ANg/wRbyjktY7WOE3QiiaJZB9PuytGIfrYcP/xRqtZ9e5jtEUeeH33s1cUBiZnjdrqz3kTfE+9OlmJ97fyfAbmrmWgaxgE9QF9yp9gi2xe69rnHHs4Tw/vGuJPT/VJyXimTFZEh9ogOwE4tUk0JGbTZz+RxDxb9blr1d9KW/XqFPUz3/wxvD4kpOiTvnP564I/a/ns+3dqztPDu2r609uOnac5iSyALRP7m9dDoQhCbZCdZNix3swENJKNop3CqhUX3obB3fJZtHGP7WgZK9EaenWKeNTy00J49dKQoqqbF/PgUskrH2wLKW9SP4sHLjrO8JpqUlIRL5S4JwCrIWVmLpeCVYUhOc2DSRax0GrD7BWFAYtZzxrXqn+0wmjLpbDlC3j54pCi/dcsYsT7Jaz799ZAWaNcN+/dehqtm+Raumy893FV1F2UuMcII4vbqkiZWfh6cet2ol+cQq+9Zm3QEjuAg+WVFKwqjHqFrlHdNNn6Nbx0YUjRz4M+oO8bRTC1Ji6gb8fDeGb4SeRk2YtPj/c+roq6ixL3GKBncS/f9geLNu6ptYsQaIuUmYWv974kvsvBjUYYVpKdATz4/vqQBUVFpbVXh0YijJYnnLcvhRfOCzn38zNnMHJBFbxRFCi769xjuK3v0VHFpyfDpKTKEZP+KHGPAXrW6utLtgcEXUJA4PN1flxmFr7R5hp+YvUjDr5uhsY2fH7r3MooxW/hh68W1UvBEG3+mJDr7lwO/zs75P3/HfNfHll7CCyoOe/Fa06mT8fDLN83mVE5YuoGStxjgJFFHf7aKNKjT8dmzFi2A0/QHpnuDBGw8M3cFLH6EWuFJGrxS1EpTw3tYsmV4sTS9uDn1zDHjRDophdoXLwexodOlI7Nm8Rbu/PBt+bokOxM3r/tNNo0rW+5DtEQL2s61cMxFdZQ4h4DjJboh+MXLy0hnrFsB9XhJwR5A8zcFLH6EVtZZQre52DVlRLtZGn48yvS2aSkGUX8NXMO12XOD5QNq7ifJdXHeTMkAWcc04ypV55Eblb8fh7xtKZVjpi6gRL3GKBlUZtFtegtjw/HUyVDxNnITRGrH7GV84Mnda24UvSeWWFRKb0nLjS1Ys06nKYUc1Pm+1zl+phMqljd5EIe29WVb6qPDxxz+9ntGXVO+4j86X6ru7CoFJfPTaXnbrNa/1hZ0yocs26gxD0GaFmrfTo2Y/aKQl33hB3BtXpsrH7EVkYmdid1g59Z+ISzkRUbLKpaNGY/N2bOZaTrI7Lw8EHGmbzT4AoWFR5Sc0z9LPYdrGD2ip20a1o/6k0//G4qK/X2fz/iuV5BhWPWDZS4xwgta7X7kY1th0dqYVWcY/Uj1gtfDEYvz4sR/memFfuuZcUarXZtxH5uzJzH1a6PyKaC96p782zVIH6sPoJmmfW469wjqefO4KmPN/PHwQogNpt+WKm3VvSUn1hY0yocs26gxD0CIp34MnJP6G2HhyBkebsdcdYbQUxasIlRM1ZHnVtGy8q2W0ctrLqTtES1IQf4S+Y8rnEtIJdy3q8+hSmVl/KTzKdFXjZPnNuBizo3p16mi94TFzriCjGzrq3UOzh6yk8srelkCMdUxBYl7jaJ1cSXnjWlVWbX3WG0i1C0dRcQiEwpKvE4YgVadScFi+ahHOCGzA+41rWA+pQxX/bkSc8gfpQtqZeZwS2ntWV0vw4h/nQ7K4WNPgOzUZdRvYPxR08pa1rhBErcbRLLiS+zvCjR4lTdtSJTctwunhraxZG6WnUntcjL4c+i37ku80Ouc33IoaKUeVU9mFw5mG2uIxncoyVTe7fl6MMaaN7HSiditiDNH3apt+mHXr0TlexNUXdQ4m6TVA4jc6rusY7ssOQTLtvP/9ospMX3L9BQHGR+1cn8u3IwG2VrLjzhCN66tBON62cZ3sdKJ2JlQVpRqQd3hqCRb9s+rWiZYOs/L9eNO0OEREOpCU2F0yhxt0kqh5Hp1b1hjtvWdeLRwen6hMv/hKVTqV78NMeWFbFQdOdf5YPYINuQl+PmX/2PZUj3VrXP07kHGHciVhekeaoluVmZrPrHebWODbf+/QurhAAp9VcoKxTRoMTdJlZWhSZrFMLofh0YPWtNrfj5gxW1k3QZoddJSLAUkx4RB36Dp0+GMm+el8+qT+JJzyCaHtOTe09rR++jm0QUn242sRjJgrRw9KJppKy9wYlC4RRK3G1iZO0lW84OrY6mQXZmrSX54QujzK55sLxS933H23zwd+QzPRElvweKhlQ+QvuTzuSp3m1pf/ghBidHTyQL0sIxGtGoZf+KWKHEPQL0rL1kytmh19HoxWNbcalY3UXJkTaX/EH1c6eS8eeuQMaFBz1XsTBvMO/89VSaNKgX+bVtEMmCtHDMrP9UmK9RpB5K3B1E7wdsdVjvJHodjUsjgyNYmzOwmlMGohCs0n14nj0d9587Aru3P+oZzupWV/H8NSczLtve/IAT2F2QFo7Zoq9UmK9RpB5K3B1ETzhdUeT+joSCVYW6HYp/U+lIVq3aEWy7k7SUFXPw6TOof2Ar/jMf9wzFc+qd3HPBsWRkxPcZ6hHu6rIS/ul/f/yc9bUSmqkoGUWsUOLuIHqpb/XKY4HfdaKHPzIjkklfO5OLVidpZdl+9k4+k6alP+NPrPukZwjtL3+YMZ1bWLpXvIhmTsVv/SfzhLsivVDi7iD5FjbPiAQ7gmDkOnFnCEoqKgOpB6xYnVbiszMEHKwIy2hpMkl78M8i9kzpSxvPTzT1lU2pHMh5t07h780b2m53PHBiTkUt+1fEC1NxF0K8AFwE/CalPMFXNh74C7DHd9i9UsoPfO/dA1wPVAG3SykXxKDeSUksEnXZtRYNXSdBm1cUFpUyasZq7pyxulacdXCmxeDIkH0lHtwuQV6Om+LSmlQDo2as1rydVl227drD/qn96CR+Cljqs3Mu45zbnuX2oEVHBasKGf32msCqz8KiUka/vUa33U5h1KGk8gI2Rd3DiuX+EvA08EpY+VNSyn8FFwghjgOGAccDLYBPhBDHSCmtzcKlOLHItmfXWtRznbhE7eXxwSl1R89aE9jHNFjQay3WqZLUr5fJ6nE1i3X0Uu4GTxR+/t126s8cTPeMHwIbjnxz2DB63PQcg10Ztc598P31terrqZI8+P76mIm7WUeaygvYFHUPU3GXUn4hhGhj8XoDgLeklOXAFiHEj0AP4JuIa5hiOD3sNrIWtaxMvdGDWZSLp1oGrHqzGYLwOund8//OO4anP/qObl/+hTNdG/CHv/zcdjjtrn6WUwwmmvW2x9MrdwKzjlRrEVjwtocKRTJR22Syzm1CiLVCiBeEEI18ZfnAjqBjdvrKaiGEuFEIsVwIsXzPnj1ahyjQtwob5ri55511FBaVIgm1MicM6kR+Xg4Cr7/f/zpWdRrYNT/kns0bZtO+SRZN3h3GbYt7c4prAwB/HHsljCui3cjnvGvvE0TBqkJ6T1xI27Hz6D1xIQWrCgGLbpfwaidHEI9CUYtIJ1SfAx7Ga+Q9DDwBXGfnAlLKacA0gO7du8cvnCTORDspqGcVC4Gulfn12L6a97CyAMkMvTmEgV3zOal1IwY9/RmPljxE3/LV4PK+V95pOPUufYbGGdq2hNYzystx6+6DetQ9H3BFz1Y8MrCT7fobuV7M3C6TFmzSdBUZTagm26Swou4QkbhLKX/1/y2EmA7M9b0sBIKzNrX0lSU9sfgROpGOQM+Pb2cSM/w6dhdV+X3wegmuPv9hD9e98A3Puiez3LU8IOrb8y9mxO8j2fltBS02f6abIfFAWWXA1eF/RoO75TNj2Q7NfWSrpOS1Jdt5Z8VO/jnoxKh3TfJ3imYT4nrP1r/Pq9V0FMHpgp38rqlORBFMROIuhGgupdzle3kp8J3v7znAG0KIJ/FOqLYHlkVdyxgTq5wwTqUj0PLjW5nE1LuO1jZ24ZgJupSSZz/7iScXbGCy+2l+yl5a8+bxgyg46kHueXcDpZ7QLeyWb/sjZOm+lg+91FPFoo17mHRZZ8POqMRTbftzMnK9mE2I61n2/o28g9vpv45ZumAnvmvJltNIkRxYCYV8EzgLaCqE2AmMA84SQnTB+/vfCtwEIKVcL4SYCWwAKoFbUyFSJlY5YeyEztm1vKIJuzQK3RNgeP8yTxW3vbGShd/v5gn3c/yU/XXNm8deDENeAlcmk3S2sHtz6Q5Li7oKfWI7sGs+bcbO0z2u1FPFXTPXWN420Mz1YncrRK0kYv7vjtV0wdF+15Ipp5EiebASLXOFRvHzBsc/CjwaTaViTbx2nrcaOheJ5RVN2GUkOwHt+KOEgc98zR8Hy3g8cxr/y/6i5s1jzoehr4GrJuWAUfoDKwgIrHDVS+sQfk0rzy2aTjHctWVUL7PvltbxkaLi7xVaRBMtk5L4hTQ4ykQv4CHa+OXR/TqQ43aFlGkJiZHlFQus1gvgq82/02bsPM54/FPuKn+GLdlXclmmT9iPOhvu3wPDZ4QIO0SfT0dCoP1X9LS2+QaYP7fwyB5/NJGdORD/8zPqcPydbfhzjsV3Te9cFX9ft6lz6Qf0dp4Px4mETlat60gsr2jznBjVS0rJf7/4mYkfbgQkD2W+xNWZH9dcoO0ZMHwWuLNr1cl/TSP73ErcPdS03x8V8/rS7Vgx/M0s1mjXIphlxwzfgCOadMFWiMXKaEXqU+fE3eiHH76s3qn9QM2uE8nKx2j9rFr1KvNUccdbq1iw/ldA8kDma1yf+WHg/TXiWLb1f51Luh9V63pWc71rJS47WF6pGfYY3P5HBnbikYGdQjqQjCjSF0eD0XcofAI6knTBdudfYrEyWpH61DlxN/KDhi+rjxeRWF5O+llf/GoLD8/bgDfqUDI2801uzpwbeH9V9dFcUXEfZdQj573NVLuya4nRXTPXmPrTgy3a8PO1Jir7dGxW6xrB52qdFw+LNZI5i2CMOvxIR2ThAu93TSmBr7vUOZ97JIIZa+z6ge8vWKfr9rBjtS7+yetPf3DuBqql5P8yZ7A1e0RA2DeKdhxX9gKXVjxEGd6dj8J92n4xMhJ2vTb5V4qOmrGa8HTtEpi9ojCwelSLgV3zGdwtP+DfdwnB4G6xz7poZ87CLpHOv2jNJd3zzjrD5xcJeqt7FclHnbPcB3bNDyTICieRE1BW/cAjpn/D1z/9ofmeVYH535c/88i87wOv73DNZpR7duD1xupW/C3nMX4s1p6PCO4EzfzPetZsuIUanjIYvKJ254zVgQVG4c+nYFUhs1cUBjqWKimZvaKQ7kc2jqnAx9INEumILB7hkCqePrWoc+IOMO7i41NyAqpgVaGusAPUy9QfiJVXVvH3GWuYt25XoOwWVwFj3DMDr3+qbs7Aiof5k1xEhbW5ADPROViuvWmHnS379EQkkfHdscrLHmnmyXiEQ6p4+tSizrllIPpwuEQxfs56w/eLSj21huK7iks5dcKndLh/fkDY72m4gK3ZwwPCvq36ME4sm8bZFU/wJ7mAcShfsC/cTHS06gT2RUfLNZGO8d2RunziEQ6Zjs87namTljuk3o44BasKdRNpBeMXweYNsxk6bUnIe5PbLGbA7qeh3FdwaD7zes/i/+buoJTao5iBXfNZvu2PkOXyfl+43/VhtvlzcJ2Cn3dertt2+t5wEbGzSCxVIkkidfnEIxxS5bNPLeqsuKcadhY0FRaVhgj7zK7f0eP7f8JuX0H9ZnDLEqjflP6AJytPV0wWbdxjuFw+XIz0plWDhblgVSEHyiprHePKEBxSL1O3EwsXESuCdn/BOsdzucQaK4aHVoc1YVCnmHZiKp4+tVDiniJEMvT9vO8Wjlx8H/jnTnMawa3LoMFhIccZiYmVoXjw+XpJyYKFedKCTZrZHg/xhaJaDXE0s3ILVhWGCLufVPcT601sThjUyVIoZqSoePrUQol7imAnT8llrs+Y5J4Gi72vD8hsRmQ/w7XnnQKbPUxaUDs9rd376g3FrVh3eh1Gsc9ityMiRh3TpAWbLI0kUo10nEhWOE+dFHenfLDx9OVa8W0PyviCJ7OmBl6XSzdnlj/JbppAOYyetQYEIZtOO51oy++n92d/9MeeA4Gc51ZWljohIkYCnsp+YjWxqbBCnRN3p2J1YxHza9RZDOyaz1ebf+ftlTtDzmmY4+bM8s+ZkvV0oKxKCs6smMJO2STkWC1XiJnFZ3corhV7PmPZDmZ8uyPQqWgJeyx8t0b511PZT6wmNhVWqHPi7tSQ1umhsV5nUVlVzdc/7eXdsFDCWTefwskHv4BZwyGrpvy08n+zN7M5pTbS6DuZaEvruWh1KuBdUVotpSOjHqubhQtgRK/WKe1aUBObCivUOXF3akjr1HX8oqRliZV6qvi/t9cGXrdqnMPbN5/K4YWfwEttQ469POtZvt2fR4u8HCb4EnNZ9dHHIxZaiyop2Tqxv+ExVlxfRhOMsY4gSQRqYlNhhTon7k4Naa1cx0yYrGZSvKRzCyZddiL1fvoYnjw89M3blkPT9szUOC/82u4MEeJzh/jFQmsRnvM9/HmFp8eNZKWq3mbhyY7WswjfdzWWkTGK1KfOrVB1KumT2XWsJHKysgQ/Py+HKd33Uu+RxvDm0Jo3bl0G44uhaXvN87RW4U66rDOThnSO6cpcreeih9/3XrCqkC4PfsSdM1aHPK/Xl2y3lEQr3SYYtb47ry3ZHvOkYIr0os5Z7k4Nac2uY8Unb2bh9nWv54WyR+H1oMK/fgOHH2e5jnrhg7Ei/LnoRcaAt3MxGr1YDWNMtwlGK51+qsfqK2JPyop7NGGITsXqRrr45/cD5QwLSw0QTK+MDbyV9Uho4U1fQvMTTevkdHjm/QXrQsIar+jZKrAzkh7Bz6WtwebW/k07rCYQ8xPJStVUwuqII1VHJor4kJLingqpR/WsSQl0f+STwOvgTZZPFhuZVe+hkOMXnTmL+5dm8svkHbTI+73WCkwzH/WoGatZvu0PU0HW4v6Cdby2ZHvgdZWUgddWr6f3HPJy3Azsms+oGasNzxeEWvCRrFSNJbFY62B13iJVRyaK+CCkxd3oY0n37t3l8uXLLR+vt8Tdnztc6wcH8f3xm02W3t//WG44vR0Fqwr54MP3mFZxT+gBNyykYM8RmhbphEFeYdUK89P6NAXw1NAuttt71D0faLpUXELw04QLLV1DL5WA39ev91n6jxvcLb/WRGKydOBmbXPyuuE4cR9F6iOEWCGl7K75npm4CyFeAC4CfpNSnuArawzMANoAW4HLpZT7hBACmAxcCJQA10gpV5pV0K64tx07z1DEakWJuATI0HjrWP84KququfJ/S1myJTT/+hs39OTUo5t6X+xcAf8Li3i47iNo3RMw7sTA3Gcffo7d6Io2Bi6V4BBGK1FBRvlftISsUa6bcRcfn9Tipff5OBG/byVaJpmfjSI+GIm7FbfMS8DTwCtBZWOBT6WUE4UQY32v7wYuANr7/vUEnvP97yhGE2iai2iq7K/MjJS9B8q5YvoSfvj1QKDssEPq8e6tvQOizC+rYdqZoSde+yEceWpIkZNRIJGc49KZDA0OYbTiIjOam0jlmG29Z+p/ZtG4C1UOF0W0mIq7lPILIUSbsOIBwFm+v18GPsMr7gOAV6R3OLBECJEnhGgupdyFgxhNoJn5cIOJdMGRlgit21nMxU9/FXJ8v+MPZ/KwrmT7QwN3r4Opp4Uc89WpL3L3yjx+eW4fLfIWhlxT11+d6yY3K9OW5W7mn9Vq2xU9W4X43P30atfIdPGVnY4zVYXMim9cRbUoEkWkce6HBwn2bsC/siYf2BF03E5fWS2EEDcKIZYLIZbv2bPH1s2NdlKyM8lk51i9uPV73llLm7HzQoR97AUd2TLhQv57VXevsP+6AcY3DBX2q96lYMAG/vJlrm788uh+HbwupTAOlFXSp2MzzTj73kc1JvwMs8gRvbZ1P7IxvY9qXOv4JVv2BWLS9bDT8aQqVmP6VVSLIhFEHS0jpZRCCNuzslLKacA08Prc7Z6vZ+1pWfV6Pnc7oXJ6cetvLqvpy169vgent6/Zgo49m+CZHqEXGvE2tD/Xe82JCzWvedfMNYyasZoWeTlkZohabiVPtTdqpVGum3qZGRSXekJGEnYjOIxi8rWo0skVE4wAzb1T0wmrMf0qqkWRCCIV91/97hYhRHPgN195IdAq6LiWvrK4oefD1SqzIzxG1teXY/rQqnFuTcHvP8LT3UIPuuIt6HCBpWsG+2yN2FfiIcftiigSJrgDiEXOcwncOWM1kxZsShkfeiQEGxlWNxnRI5W2A1QkP5GK+xxgJDDR9/97QeW3CSHewjuRWuy0v90KTq/M/K6wWFcA8/NyaoT9j59hStfQA4a+BsderHmunTwseoT7dK1McFrNaWO0utQqybgGwQ52BDeayeFUWLuhSC2shEK+iXfytCnwKzAOKABmAq2BbXhDIf/whUI+DZyPNxTyWimlaYyj3VDIePHuqp2MmrFG9/1AOGUbD0zuHPLebRW3s+rQPqa5z62IrBkC2OILTTSKG/eHFz74/nrbm1NHS16Om9XjzovrPaMlVnHsWpit3VAotIgqFFJKeYXOW2drHCuBW+1VL7moqpY8+P56XvlmW0j5S9eeTFGJJ8Qq+8fph9BvzgkgqwPH3VFxK+9V9/a+MLG+rPpsG5lExwT7dI1GAvtKPNw1a42hz1wQmcXuyhCG1y0q9aScDz6e29mlW/IzReJJyfQDdrA6rC4qqeCq55exrrA4UNYwx837t51G6yY1/vSBXfOhuBCmdIGPKwLlK7pOYMg3R9rejNmKz9a/mMfMp1uwqlB3laofIwH2W4lG+WC08I8IzHLIh7uPkt2/rCeshUWl9J640NE6p1vyM0XiSWtxt+LH3PDLfi6c8mXIeWd1aMazI04iNyvs8fy5G/7TDSpqFihNyLyVY/vf6tuMWd/6siJmZj5bK5koo/GQHyyvpGBVoeH2dOHXD+58/B3QnTprDfximez+Zf9nZfQsna5zn47NNNcU9OnYTONohcKclMwtYxUjP+aY8ztwx1uhIjTqnGO4/eyjEWGbSHDgN29IY+m+QNG9nut5o8rrmcpxuwz95nk5bsorq2Puu9VLy2AHfz6X4ARketTPcuF2ZVBU6gmsZs3Py6GopIKDFbXP9Y8Mktm/bHcexKk6J/MzUSQv0aYfSFmMhtXBwv7CNd3p2/Hw2gce/B2ePQUO/hYoejLzL0w50CfksFJPle5SfQEIQVx8t1aib1wZggz09zUt9VSxaOMeBnfLD6T61aOkogqJt13B4ZvuDIHbJXR3fEpm/7LdFMRO1TmZn4kiNUlrcTcSuwb1Mpn7t9No07R+7TdL/vCuJt1fE6K/7vgx3PzTKbrXq5KylgXv34z5dY3hNjib/gC8C7hGv71GM5cO1PjGAUP/eGFRKbNXFJpOquq966mW5OW4qV8vU7OuyexftvuZOFVnO88kFeYrFIknrcX9yp6teSxslWWGgAmXdmJoj9a1jp+3dANd5g8kBGktSgAAD0RJREFUX/5aU3jOgxTUv8wnmvo//Hzfj0zrR7do4x5LP1w72RN1fb5hiuvOEEy6rLOmf98oq2G04ZnFpR7d0Mdk3lzDKP+8lmvNqTpbfSbJPl+hSB7SUtznrv2F295YVau8RcNsxpzfsfaPoKyYP58+k/4HtgSK/uW5jOczhjChficefH+9rjUMNT9COykRAEoqKgPhgXo/2uXb/tDtHMJdO5MWbKrlbvFUS133j56gWBF2s6gcI4s2mTNB6j2T8ZfUjHhiUWerzySe4ZmK1CZtxL26WjLhw++Z/uWWkPLpV3fn3OM0/OkA5X/C8+fBbxs4xFc0uXIQT1UO8b6o8v5ojBb85Fv4kfvfGz9nPUWlNdfaV+IJWF16P9rXl2w3FNFgN4IVv2346EBrMww9l01wnvLwXZ+CsWLRhouZP49NogXKasRSrO5tdn3lm1dYJeXFfX+Zh+te/Jbl22oiWbLdGcy7/XSOatYAqC1oY89uycUrrofdawPnPFM5gEmVl0NYTkWzCUqrkQwDu+YzacGmEHGHGqtL7z5m0S/BFrKZ31ZrdDB7RaFm1I6VlZndj2wcqHtwtIwVizaZ3QvJnII4mecrFMlFSov7zn0lnPbYosDrU9o1YfrI7jSoV9OsYBHJppynS/5B13k/1lzk1L/BuQ/zxmOLwKb1k5fjDrmP2ZDaKHonEsItZDO/rd7o4M6wfVatugiiEUHlXoiMZJ6vUCQXKS3uuVmZnJB/KGe0b8bofh1qx6fjFZFqTykzsybQI6NmcnWm6yIuv/81b5wi+n5xPdwZIuCH1bJCR89aw4Pvr6eopCYdr57VpRdGaYTWNnThotwwx40QMMqXndGoEwnf+DrW1mtddy9EGvGSzPMViuQirRcxUVnO4gfP4lTXhkDRK5Xn8o/KaxCIQLItP1bS4EJtP7tRsi4/eouDrE5gatXByCUUSVIyOxtfR0ss9x9NduKZkEyR3hgtYop0J6bkprICXr0UHjksIOxvVvahbdlr/KPyWkBo+igHds3n67F92TKxf81+p2EEi2rviQtpO3aeJbeKf3GQ1g5SevcyotCX0iCYglWF9J64kDZj53HnjNW2O41o0/vaQW8XoyopNXelSifsbo6iUERCSrtlalHlgRlXwg/zA0XbWg3kgq1DKam0twuTkW8z0lS9vxSV6ro79PKxGBE8AelE+mCXhlsrVljJiJmuPvi67pJSxIf0sNyrKr2i/nDTGmHvdBn84w+OvP5l/jmos+Z+q0YY7dNqd4m6n7xct2b5wK75IZOzVgm29iKtUzC92jWK6nw9/COKtmPn0XviwoA1HjxSqtYZNaSj4OlFtqiIF4WTpL7lPvsGWDer5vVxA2DwC+CqaVqkk4N650UqOAfKahYthTP+kuNrWd7+hUJ5Oe5aIZThdbFSJzP//ta9zqVD8L9XWFQasuBJL+QxL9etuZ4gHQVPRbwo4kFqi/uutTXC3vEiuOwlcNm3gK1QsKow6h2MjFaLmkVB6E1A+sXPLGmYSwgmDOrEXTPX6PrW7XRaBasKGT1rTWBFrD9CyE+weJnluL+/YJ3mc3W7RFoKnop4UcSD1Bb3w0+AkXOhVU/IzIrqUmZWqFFCLjBfju/HSECNRhhm1p5RKGdwJMbybX9o5g0He1by+DnrNVMdjJ+znvr1Mk1dRMG53fUSq9XPykxbwUvmhVKK9CC1xT0jA9qeHvHpVl0H4+cY55bJN1mOH0ykbgY7G3kEW/AuIRjcrUZIuh/ZWDOlgV0rWc9NVFTqoVjnvWD8z8FoUwwr11F4UZkiFeGktrhHQXh0iZ7rAPSFDLwWuz800r8c37+A6GBFpW5O80iwYu2VVFSGvK6SktkrCul+ZOPAZLCWmDppJZu5iKzkdvdfR2FOMqdyUCSOOivuVqJLghNa6ZEhBG3HzgtYS8ELi+JhTemNPoIJ9nHriamelazXhkY6E6Dg7WDcGSLEbeOvW/gCMKMt/Zz2t6erdatSOSi0iErchRBbgT+BKqBSStldCNEYmAG0AbYCl0sp9+ldI9bo/aCtTB62yMsxPS54B6JwaynWflWz0Ucw/nboiamEWps+G1mE4y4+XnceYl+JB7dLkJfjprjUozmH0XviwsAIJ3zXJv8mJ04+u3S2blXcvEILJ+Lc+0gpuwQtgR0LfCqlbA986nudEPw/6EJfOoHgVY9mQ37hOz7DxsKeeK8yHD9nveXYdn979VaGQk3Eiz8O3cwinDSks+7qWk+VpH69TLZM7M/XY/uGTk7PWhP4TIpKPVRVSRrlugPrCZ4a2iWQ48Yp0nlVqIqbV2gRi0VMA4CXfX+/DAyMwT0sYfSD1hI5EfS/347UChvUE0eIzlrSW+yjd6zRXEA4fhdH8OIsLTzVklEzVlOwqtDUIvQvQtLr/rTO14qyqQaKoggxtUI6W7da32UVN6+IVtwl8JEQYoUQ4kZf2eFSyl2+v3cDOjtlxB6jH7TWCtSnhnYhPy9H073hEsJSPphIrSWjUYYWdizORrnuWtkjjZKOSbxx6g11Vs2Gt9GO5ajXIUnfv1jllEln69ZoNbWi7hLthOppUspCIcRhwMdCiI3Bb0oppRBC0xXs6wxuBGjduvZ+pk5gtrGBlk98lE6Ol2opa2WRDPc5R7Poxu6kmFWLM8ftCmyKbYdSTxXZ7oxaq1q1LEKzGPzgeQ+r93Z6MjDdV4WquHlFOFFZ7lLKQt//vwHvAj2AX4UQzQF8//+mc+40KWV3KWX3Zs2aRVMNXSIZrtqy8MK7LY1uzKqrxWiUoXUNvXrmujNoFJTDpl6m/kfcSCfXjZ+iEo8li9DIcgwfkVjFaXeJsm4VdY2I87kLIeoDGVLKP31/fww8BJwN7JVSThRCjAUaSynHGF0rZvncsR/+ZjXXtl46gOCUwHbydutdr1GumzJPda1r6OWG1yvXuqfZyluznPFWsJLrPlb3VijSHaN87tG4ZQ4H3vXtfpQJvCGlnC+E+BaYKYS4HtgGXB7FPaLG7nDVat4PKxN0WtEsei4HPbeBlGhe47Ul28nLcZPtzgjZ7cmOe8f/Witnjh2XhVEHamSBC7wJww6UVYZMsqaTu0ShSBQRi7uU8megs0b5XrzWe8pipUOwshm1WSbH8HtC7U5Fbw4AvJOTOW4XTw3tEjhf73g9kfW3NdIFPmbx43rPKXyEk46LixSKRFJnV6hGi5XNqPXQ85drdSpme5+GW+VmnY4ekU7ImY0UrExkqslAhcJ50mOzjgRgNkFn5I6w43IwWnTkJ/he8Y55thILryYyFYr4oyz3KDCyOPUs6PCYcyv3AGMLPtgqj3eucCsjBWWZKxTxR4l7jNBzR0QScx7sF7cSqx1PMR3dr4Oj8f4KhcIZlLjHiFhY0Em7g4+FeH+FQhFfIo5zd5JYxrkrYouVeH+FQhEbjOLc1YSqIirSOSGXQpHKKLeMIiL8sel64750SMilUKQyStwVttGa2A1GrTBVKBKPEneFbYy2KAzfRk+hUCQGJe4K2+j504M3C1coFIlFTagqbJPOG18oFOmCEneFbdS2bgpF8qPcMgrbJO1iKoVCEUCJuyIiVL4YhSK5UW4ZhUKhSEOUuCsUCkUaosRdoVAo0hAl7gqFQpGGKHFXKBSKNCQpUv4KIfYA24CmwO8Jrk68UW2uG6g21w3i3eYjpZTNtN5ICnH3I4RYrpebOF1Rba4bqDbXDZKpzcoto1AoFGmIEneFQqFIQ5JN3KclugIJQLW5bqDaXDdImjYnlc9doVAoFM6QbJa7QqFQKBxAibtCoVCkIXEXdyFEYyHEx0KIzb7/G+kcN18IUSSEmBtW3lYIsVQI8aMQYoYQIis+NY8cG20e6TtmsxBiZFD5Z0KITUKI1b5/h8Wv9vYQQpzvq+uPQoixGu/X831uP/o+xzZB793jK98khOgXz3pHSqTtFUK0EUKUBn2mU+Nd90ix0OYzhBArhRCVQoghYe9pfseTnSjbXBX0Oc+JW6WllHH9BzwOjPX9PRZ4TOe4s4GLgblh5TOBYb6/pwJ/jXcbYtFmoDHws+//Rr6/G/ne+wzonuh2WGinC/gJaAdkAWuA48KOuQWY6vt7GDDD9/dxvuPrAW1913Eluk0xbG8b4LtEtyFGbW4DnAi8AgwJKtf9jifzv2ja7HvvQCLqnQi3zADgZd/fLwMDtQ6SUn4K/BlcJoQQQF/gbbPzkwwrbe4HfCyl/ENKuQ/4GDg/TvVzih7Aj1LKn6WUFcBbeNseTPCzeBs42/e5DgDeklKWSym3AD/6rpfMRNPeVMW0zVLKrVLKtUB12Lmp+h2Pps0JIxHifriUcpfv793A4TbObQIUSSkrfa93AqmwY4SVNucDO4Jeh7ftRd+w7oEkFgezNoQc4/sci/F+rlbOTTaiaS9AWyHEKiHE50KI02NdWYeI5nNKxc8Yoq93thBiuRBiiRAibsZoTHZiEkJ8Ahyh8dZ9wS+klFIIkRaxmDFu8wgpZaEQ4hBgNnAV3uGfInXZBbSWUu4VQnQDCoQQx0sp9ye6YgrHOdL3+20HLBRCrJNS/hTrm8ZE3KWU5+i9J4T4VQjRXEq5SwjRHPjNxqX3AnlCiEyfFdQSKIyyuo7gQJsLgbOCXrfE62tHSlno+/9PIcQbeIeJySjuhUCroNdan4//mJ1CiEygId7P1cq5yUbE7ZVeZ2w5gJRyhRDiJ+AYYHnMax0d0XxOut/xJCeq72bQ7/dnIcRnQFe8PvyYkgi3zBzAP0s+EnjP6om+H8QiwD8bbev8BGKlzQuA84QQjXzRNOcBC4QQmUKIpgBCCDdwEfBdHOocCd8C7X0RTVl4JxDDowOCn8UQYKHvc50DDPNFl7QF2gPL4lTvSIm4vUKIZkIIF4DPomuPd4Ix2bHSZj00v+MxqqeTRNxmX1vr+f5uCvQGNsSspsEkYOa5CfApsBn4BGjsK+8O/C/ouC+BPUApXh9XP195O7w/+h+BWUC9RMxEx6jN1/na9SNwra+sPrACWAusByaTxFEkwIXAD3gtk/t8ZQ8Bl/j+zvZ9bj/6Psd2Qefe5ztvE3BBotsSy/YCg32f52pgJXBxotviYJtP9v1mD+Idla0POrfWdzwV/kXaZuBUYB3eCJt1wPXxqrNKP6BQKBRpiFqhqlAoFGmIEneFQqFIQ5S4KxQKRRqixF2hUCjSECXuCoVCkYYocVcoFIo0RIm7QqFQpCH/D6xSGlG+4ks2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUBvTRt7vUgs"
      },
      "source": [
        "**Opdracht drie** Gebruik nu alle diabetesdata en train een lineair regressiemodel. Train nu een deep learning model met betere validatie score. Vergelijke de MSE op de test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3U3SxHPvUtt",
        "outputId": "c59968b6-3e6d-48f9-bff6-051fef1e4f15"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1)(dense1)\n",
        "\n",
        "regressie_model2 = models.Model(input,output)\n",
        "\n",
        "regressie_model2.compile(optimizer=SGD(5e-5,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "history2 = regressie_model2.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm2 = LinearRegression().fit(x_train,y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 31466.9095 - val_loss: 21786.1094\n",
            "Epoch 2/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 30450.6745 - val_loss: 16715.5254\n",
            "Epoch 3/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18753.0291 - val_loss: 19271.3105\n",
            "Epoch 4/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 11429.6416 - val_loss: 5540.9536\n",
            "Epoch 5/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8814.9051 - val_loss: 4321.7031\n",
            "Epoch 6/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8764.7412 - val_loss: 5510.4775\n",
            "Epoch 7/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7176.9252 - val_loss: 4280.9629\n",
            "Epoch 8/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6581.7689 - val_loss: 5724.6885\n",
            "Epoch 9/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5071.5053 - val_loss: 3876.5503\n",
            "Epoch 10/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4570.6866 - val_loss: 3671.7170\n",
            "Epoch 11/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4685.9329 - val_loss: 4428.8701\n",
            "Epoch 12/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3764.9780 - val_loss: 3404.1941\n",
            "Epoch 13/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3553.3928 - val_loss: 3599.0881\n",
            "Epoch 14/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3573.0544 - val_loss: 3761.6865\n",
            "Epoch 15/40\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3596.5692 - val_loss: 3560.1504\n",
            "Epoch 16/40\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 3305.9730 - val_loss: 4320.9741\n",
            "Epoch 17/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4101.7917 - val_loss: 5827.8984\n",
            "Epoch 18/40\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5212.2337 - val_loss: 4075.6277\n",
            "Epoch 19/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3452.6720 - val_loss: 3470.8672\n",
            "Epoch 20/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3905.8315 - val_loss: 3143.7361\n",
            "Epoch 21/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3405.6420 - val_loss: 3494.5125\n",
            "Epoch 22/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3562.0836 - val_loss: 3191.7456\n",
            "Epoch 23/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3742.8825 - val_loss: 6816.6274\n",
            "Epoch 24/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5118.8416 - val_loss: 3287.6216\n",
            "Epoch 25/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3270.2448 - val_loss: 3239.8767\n",
            "Epoch 26/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3230.1198 - val_loss: 3821.4089\n",
            "Epoch 27/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3387.4546 - val_loss: 3947.5071\n",
            "Epoch 28/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3110.5699 - val_loss: 3441.9514\n",
            "Epoch 29/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2940.1941 - val_loss: 3172.6807\n",
            "Epoch 30/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3006.4791 - val_loss: 3197.2695\n",
            "Epoch 31/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2985.6192 - val_loss: 3677.9568\n",
            "Epoch 32/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2901.0702 - val_loss: 3315.5876\n",
            "Epoch 33/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2896.9745 - val_loss: 3749.3010\n",
            "Epoch 34/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3247.5203 - val_loss: 5529.1733\n",
            "Epoch 35/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4083.4211 - val_loss: 3306.3855\n",
            "Epoch 36/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3276.4571 - val_loss: 3860.1350\n",
            "Epoch 37/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3587.0539 - val_loss: 5154.7837\n",
            "Epoch 38/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3227.3764 - val_loss: 3306.2380\n",
            "Epoch 39/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3040.3156 - val_loss: 3355.6194\n",
            "Epoch 40/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3311.5794 - val_loss: 3290.8877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGku2miOwpW",
        "outputId": "8572a68a-8e26-44d0-9b19-01a0e4431f47"
      },
      "source": [
        "print('Linear regression test MSE', np.mean((regressie_model2.predict(x_test)-y_test)**2))\n",
        "print('Deep Learning test MSE',np.mean((lm2.predict(x_test)-y_test)**2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear regression test MSE 8377.014415610753\n",
            "Deep Learning test MSE 2900.1732878832318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDGkcDYvU0D"
      },
      "source": [
        "**Opdracht vier** Ontwerp en train een meerlaags classificatiemodel op de breast cancer dataset. \n",
        "\n",
        "*   De activatie van je laatste laag moet voor binaire classificatie 'sigmoid' zijn (als er meer dan twee klassen waren geweest hadden we 'softmax' gebruikt)\n",
        "\n",
        "*   Als loss kan je 'binary_crossentropy' gebruiken\n",
        "\n",
        "Er zijn veel metrieken die je kan bekijken, bijvoorbeeld: precision, accuracy, recall, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAt2b6hfvU5p"
      },
      "source": [
        "# inladen data\n",
        "data = load_breast_cancer()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1,activation='sigmoid')(dense1)\n",
        "\n",
        "logregressie_model = models.Model(input,output)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3F_B5SkRa77",
        "outputId": "20c479e6-b686-4572-9ab5-fd14c84518fb"
      },
      "source": [
        "logregressie_model.compile(optimizer=SGD(1e-4,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Precision','Recall']\n",
        ")\n",
        "\n",
        "history2 = logregressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=100,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 82.9590 - precision: 0.6441 - recall: 0.5143 - val_loss: 100.5439 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 61.7012 - precision: 0.6693 - recall: 0.6476 - val_loss: 51.7719 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.2457 - precision: 0.6955 - recall: 0.6843 - val_loss: 24.8472 - val_precision: 0.6667 - val_recall: 1.0000\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.8151 - precision: 0.7279 - recall: 0.6374 - val_loss: 24.3497 - val_precision: 0.6667 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.8133 - precision: 0.7653 - recall: 0.7248 - val_loss: 8.6325 - val_precision: 0.7342 - val_recall: 1.0000\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.9332 - precision: 0.8309 - recall: 0.7938 - val_loss: 13.0614 - val_precision: 0.7160 - val_recall: 1.0000\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 4.8806 - precision: 0.7866 - recall: 0.7484 - val_loss: 7.1299 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0907 - precision: 0.8994 - recall: 0.9087 - val_loss: 5.3904 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3979 - precision: 0.8735 - recall: 0.9094 - val_loss: 2.9295 - val_precision: 0.8507 - val_recall: 0.9828\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.2907 - precision: 0.8980 - recall: 0.9073 - val_loss: 4.5772 - val_precision: 1.0000 - val_recall: 0.3621\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5941 - precision: 0.9076 - recall: 0.7303 - val_loss: 1.9957 - val_precision: 0.9268 - val_recall: 0.6552\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2278 - precision: 0.9331 - recall: 0.8475 - val_loss: 8.1663 - val_precision: 1.0000 - val_recall: 0.1379\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8830 - precision: 0.9154 - recall: 0.6556 - val_loss: 1.3258 - val_precision: 0.8615 - val_recall: 0.9655\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1814 - precision: 0.9149 - recall: 0.8952 - val_loss: 3.0928 - val_precision: 1.0000 - val_recall: 0.4310\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6920 - precision: 0.9418 - recall: 0.8070 - val_loss: 0.9468 - val_precision: 0.8889 - val_recall: 0.8276\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1372 - precision: 0.9097 - recall: 0.8708 - val_loss: 2.7138 - val_precision: 0.8056 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9405 - precision: 0.8706 - recall: 0.8915 - val_loss: 7.2541 - val_precision: 0.7160 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2120 - precision: 0.8443 - recall: 0.9303 - val_loss: 5.5131 - val_precision: 1.0000 - val_recall: 0.2586\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.8561 - precision: 0.9374 - recall: 0.7499 - val_loss: 1.1072 - val_precision: 0.9149 - val_recall: 0.7414\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3580 - precision: 0.9116 - recall: 0.7936 - val_loss: 0.8474 - val_precision: 0.8750 - val_recall: 0.9655\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8427 - precision: 0.8980 - recall: 0.8936 - val_loss: 0.7848 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6960 - precision: 0.9168 - recall: 0.9171 - val_loss: 0.7311 - val_precision: 0.9107 - val_recall: 0.8793\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8340 - precision: 0.9220 - recall: 0.8935 - val_loss: 0.6815 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8500 - precision: 0.9025 - recall: 0.8927 - val_loss: 0.6634 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7264 - precision: 0.9179 - recall: 0.9070 - val_loss: 10.2044 - val_precision: 1.0000 - val_recall: 0.0517\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4395 - precision: 0.8812 - recall: 0.4957 - val_loss: 0.9056 - val_precision: 0.8615 - val_recall: 0.9655\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9693 - precision: 0.9235 - recall: 0.8654 - val_loss: 3.5025 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6052 - precision: 0.8803 - recall: 0.9325 - val_loss: 0.7396 - val_precision: 0.8750 - val_recall: 0.9655\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5847 - precision: 0.9202 - recall: 0.9172 - val_loss: 3.2394 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1761 - precision: 0.8633 - recall: 0.9187 - val_loss: 1.7557 - val_precision: 0.8169 - val_recall: 1.0000\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2183 - precision: 0.8709 - recall: 0.9251 - val_loss: 0.6524 - val_precision: 0.9107 - val_recall: 0.8793\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8067 - precision: 0.9086 - recall: 0.8830 - val_loss: 0.6044 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6333 - precision: 0.8945 - recall: 0.9337 - val_loss: 0.5926 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6027 - precision: 0.9192 - recall: 0.9087 - val_loss: 1.4271 - val_precision: 0.8286 - val_recall: 1.0000\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6516 - precision: 0.9135 - recall: 0.9521 - val_loss: 0.5920 - val_precision: 0.9123 - val_recall: 0.8966\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5219 - precision: 0.9296 - recall: 0.8933 - val_loss: 0.9235 - val_precision: 0.8507 - val_recall: 0.9828\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5330 - precision: 0.9148 - recall: 0.9372 - val_loss: 2.5206 - val_precision: 1.0000 - val_recall: 0.3793\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5954 - precision: 0.9013 - recall: 0.7192 - val_loss: 3.9135 - val_precision: 1.0000 - val_recall: 0.2759\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2367 - precision: 0.8962 - recall: 0.6679 - val_loss: 0.6645 - val_precision: 0.8906 - val_recall: 0.9828\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5522 - precision: 0.9011 - recall: 0.9217 - val_loss: 0.5380 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4004 - precision: 0.9336 - recall: 0.9275 - val_loss: 1.2455 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8126 - precision: 0.8882 - recall: 0.9308 - val_loss: 0.6858 - val_precision: 0.9583 - val_recall: 0.7931\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6612 - precision: 0.9030 - recall: 0.8792 - val_loss: 1.8181 - val_precision: 0.9667 - val_recall: 0.5000\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3917 - precision: 0.9205 - recall: 0.7990 - val_loss: 1.8685 - val_precision: 0.7733 - val_recall: 1.0000\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7798 - precision: 0.8802 - recall: 0.9133 - val_loss: 0.4894 - val_precision: 0.9016 - val_recall: 0.9483\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5247 - precision: 0.9138 - recall: 0.9292 - val_loss: 2.7708 - val_precision: 0.7436 - val_recall: 1.0000\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.2687 - precision: 0.8401 - recall: 0.9127 - val_loss: 0.5359 - val_precision: 0.9107 - val_recall: 0.8793\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4791 - precision: 0.9201 - recall: 0.8898 - val_loss: 0.4775 - val_precision: 0.9123 - val_recall: 0.8966\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6753 - precision: 0.9317 - recall: 0.8545 - val_loss: 0.7707 - val_precision: 0.8382 - val_recall: 0.9828\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4586 - precision: 0.8909 - recall: 0.9348 - val_loss: 1.5267 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4989 - precision: 0.8948 - recall: 0.9533 - val_loss: 0.5283 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4754 - precision: 0.9151 - recall: 0.9565 - val_loss: 0.4528 - val_precision: 0.9153 - val_recall: 0.9310\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4395 - precision: 0.9201 - recall: 0.9305 - val_loss: 0.7100 - val_precision: 0.9565 - val_recall: 0.7586\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7037 - precision: 0.9219 - recall: 0.8157 - val_loss: 0.7180 - val_precision: 0.8507 - val_recall: 0.9828\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4471 - precision: 0.9144 - recall: 0.9398 - val_loss: 0.4398 - val_precision: 0.8871 - val_recall: 0.9483\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3637 - precision: 0.9246 - recall: 0.9279 - val_loss: 0.4301 - val_precision: 0.8871 - val_recall: 0.9483\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3955 - precision: 0.9207 - recall: 0.9287 - val_loss: 0.8045 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3085 - precision: 0.9132 - recall: 0.9510 - val_loss: 1.0235 - val_precision: 0.9744 - val_recall: 0.6552\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7871 - precision: 0.9275 - recall: 0.8296 - val_loss: 0.5576 - val_precision: 0.9796 - val_recall: 0.8276\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5198 - precision: 0.9253 - recall: 0.8878 - val_loss: 0.4752 - val_precision: 0.8769 - val_recall: 0.9828\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3107 - precision: 0.9231 - recall: 0.9323 - val_loss: 0.4177 - val_precision: 0.9286 - val_recall: 0.8966\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4883 - precision: 0.9122 - recall: 0.8978 - val_loss: 0.4691 - val_precision: 0.8769 - val_recall: 0.9828\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3534 - precision: 0.9322 - recall: 0.9400 - val_loss: 5.9807 - val_precision: 0.6744 - val_recall: 1.0000\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6996 - precision: 0.7810 - recall: 0.8805 - val_loss: 0.4071 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5405 - precision: 0.9018 - recall: 0.9096 - val_loss: 0.6562 - val_precision: 0.8382 - val_recall: 0.9828\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3636 - precision: 0.9294 - recall: 0.9633 - val_loss: 2.0464 - val_precision: 1.0000 - val_recall: 0.3448\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2445 - precision: 0.9008 - recall: 0.7497 - val_loss: 2.2594 - val_precision: 0.7436 - val_recall: 1.0000\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0446 - precision: 0.8603 - recall: 0.9130 - val_loss: 0.9699 - val_precision: 0.8028 - val_recall: 0.9828\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7355 - precision: 0.8674 - recall: 0.9105 - val_loss: 0.8739 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8170 - precision: 0.9008 - recall: 0.9535 - val_loss: 0.4080 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3736 - precision: 0.9206 - recall: 0.9082 - val_loss: 0.4860 - val_precision: 0.8906 - val_recall: 0.9828\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4468 - precision: 0.8859 - recall: 0.9346 - val_loss: 0.7002 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3764 - precision: 0.8920 - recall: 0.9608 - val_loss: 1.0092 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4013 - precision: 0.9103 - recall: 0.9545 - val_loss: 0.9369 - val_precision: 0.9744 - val_recall: 0.6552\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6529 - precision: 0.9418 - recall: 0.8518 - val_loss: 0.4037 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3559 - precision: 0.9229 - recall: 0.9475 - val_loss: 1.1068 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5985 - precision: 0.8732 - recall: 0.9325 - val_loss: 1.5043 - val_precision: 0.9630 - val_recall: 0.4483\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8240 - precision: 0.9213 - recall: 0.7493 - val_loss: 0.3691 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3598 - precision: 0.9296 - recall: 0.8934 - val_loss: 0.4250 - val_precision: 0.8906 - val_recall: 0.9828\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4095 - precision: 0.9034 - recall: 0.9053 - val_loss: 0.6230 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3842 - precision: 0.8809 - recall: 0.9600 - val_loss: 0.4206 - val_precision: 0.8906 - val_recall: 0.9828\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3749 - precision: 0.8936 - recall: 0.9527 - val_loss: 1.1930 - val_precision: 0.7733 - val_recall: 1.0000\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4242 - precision: 0.8786 - recall: 0.9438 - val_loss: 0.9860 - val_precision: 0.9730 - val_recall: 0.6207\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7634 - precision: 0.9354 - recall: 0.8246 - val_loss: 2.2138 - val_precision: 0.7436 - val_recall: 1.0000\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0606 - precision: 0.8195 - recall: 0.9063 - val_loss: 0.4337 - val_precision: 0.8906 - val_recall: 0.9828\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6076 - precision: 0.8994 - recall: 0.9257 - val_loss: 0.3708 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3000 - precision: 0.9330 - recall: 0.9280 - val_loss: 1.1625 - val_precision: 0.7733 - val_recall: 1.0000\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4831 - precision: 0.8978 - recall: 0.9495 - val_loss: 0.3434 - val_precision: 0.9153 - val_recall: 0.9310\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3331 - precision: 0.9145 - recall: 0.9420 - val_loss: 0.4557 - val_precision: 0.8769 - val_recall: 0.9828\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3498 - precision: 0.8991 - recall: 0.9283 - val_loss: 0.3538 - val_precision: 0.9138 - val_recall: 0.9138\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3443 - precision: 0.9129 - recall: 0.9316 - val_loss: 0.8522 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4313 - precision: 0.8819 - recall: 0.9575 - val_loss: 0.3409 - val_precision: 0.9123 - val_recall: 0.8966\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3654 - precision: 0.9168 - recall: 0.8996 - val_loss: 0.4116 - val_precision: 0.8769 - val_recall: 0.9828\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3195 - precision: 0.8982 - recall: 0.9585 - val_loss: 0.3255 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2326 - precision: 0.9217 - recall: 0.9703 - val_loss: 0.3164 - val_precision: 0.9167 - val_recall: 0.9483\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2673 - precision: 0.9229 - recall: 0.9238 - val_loss: 0.3192 - val_precision: 0.8889 - val_recall: 0.9655\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3136 - precision: 0.9053 - recall: 0.9397 - val_loss: 0.3425 - val_precision: 0.9123 - val_recall: 0.8966\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2770 - precision: 0.9327 - recall: 0.9262 - val_loss: 0.3055 - val_precision: 0.9167 - val_recall: 0.9483\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2588 - precision: 0.9225 - recall: 0.9386 - val_loss: 0.3339 - val_precision: 0.9107 - val_recall: 0.8793\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3430 - precision: 0.9110 - recall: 0.8837 - val_loss: 0.3067 - val_precision: 0.8889 - val_recall: 0.9655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahpahNKrQn-k",
        "outputId": "caed1bc3-8724-4346-88a0-74de5779dac2"
      },
      "source": [
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogReg = LogisticRegression().fit(x_train,y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxHUxcP9SCLX",
        "outputId": "c9d727fc-90d3-4fd7-fdfb-170df127c184"
      },
      "source": [
        "acc_DL = (np.array(tf.greater(logregressie_model.predict(x_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of deep learning model is',acc_DL)\n",
        "acc_SK = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_SK)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of deep learning model is 96.49122807017544\n",
            "Accuracy of Logistic Regression model is 95.6140350877193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvQQR6nvU_y"
      },
      "source": [
        "**Bonus: ensembling/stacking** Laten we kijken of we met stacking het bovenstaande deep learning model kunnen verslaan. Bij ensemblen trainen we in dit geval een netwerk met maar een laag, die de optimale combinatie van voorspelling zoekt van andere modellen. Doorloop de volgende 3 stappen:\n",
        "1. Train drie verschillende classificatiemodellen met sklearn, bijvoorbeeld randomforest, logistic regression en KNN\n",
        "2. Maak een nieuw numpy array met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_train. \n",
        "3. Gebruik dit nieuwe dataframe als input voor een eenlaags neuraal netwerk met 1 neuron (zoals we bij opdracht een hadden ontworpen). De labels blijven natuurlijk y_train. \n",
        "\n",
        "Gefeliciteerd je hebt nu een ensemble model getraind! Om te testen of dit model beter werkt dan je deep learning model moet je nog 2 stappen doorlopen.\n",
        "\n",
        "i. Maak een nieuw dataframe met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_test.\n",
        "\n",
        "ii. Doe model.predict op deze nieuwe dataset en bereken handmatig de loss en metrieken. \n",
        "\n",
        "*Nota bene: je kan de resultaten nog verder verbeteren door 4 modellen te ensemblen, waarvan het vierde model je deep learning model uit opdracht 3 is*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIca6LiuvVGS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "RF = RandomForestClassifier().fit(x_train,y_train)\n",
        "KNN = KNeighborsClassifier(n_neighbors=3).fit(x_train,y_train)\n",
        "\n",
        "ensemble_train = np.transpose(np.array([LogReg.predict_proba(x_train)[:,1],RF.predict_proba(x_train)[:,1],KNN.predict_proba(x_train)[:,1]]))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3AOEB2UxCA",
        "outputId": "0f2efc79-8cef-4c45-f692-4637c05dd58c"
      },
      "source": [
        "ensembler = models.Sequential()\n",
        "ensembler.add(layers.Input(shape=(3)))\n",
        "ensembler.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ensembler.compile(optimizer=SGD(1e-2,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Accuracy','Precision','Recall']\n",
        ")\n",
        "                  \n",
        "ensembler_history = ensembler.fit(x=ensemble_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=100,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 40ms/step - loss: 0.8136 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.7341 - val_accuracy: 0.0000e+00 - val_precision: 0.1379 - val_recall: 0.0690\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7134 - accuracy: 0.0000e+00 - precision: 0.3041 - recall: 0.3026 - val_loss: 0.6418 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6334 - accuracy: 0.0000e+00 - precision: 0.6047 - recall: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5734 - accuracy: 0.0000e+00 - precision: 0.6349 - recall: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.0000e+00 - precision: 0.6198 - recall: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.0000e+00 - precision: 0.6049 - recall: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.0000e+00 - precision: 0.6523 - recall: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.0000e+00 - precision: 0.6193 - recall: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.0000e+00 - precision: 0.6045 - recall: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.0000e+00 - precision: 0.6293 - recall: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.0000e+00 - precision: 0.6309 - recall: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.0000e+00 - precision: 0.6383 - recall: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.0000e+00 - val_precision: 0.7733 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.0000e+00 - precision: 0.8227 - recall: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.0000e+00 - val_precision: 0.8056 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.0000e+00 - precision: 0.8424 - recall: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.0000e+00 - precision: 0.8593 - recall: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.0000e+00 - precision: 0.9003 - recall: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3485 - accuracy: 0.0000e+00 - precision: 0.8880 - recall: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.0000e+00 - precision: 0.8852 - recall: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.0000e+00 - precision: 0.8666 - recall: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.0000e+00 - precision: 0.9041 - recall: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3132 - accuracy: 0.0000e+00 - precision: 0.9169 - recall: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.0000e+00 - precision: 0.8862 - recall: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.0000e+00 - val_precision: 0.8406 - val_recall: 1.0000\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.0000e+00 - precision: 0.9107 - recall: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.0000e+00 - val_precision: 0.8529 - val_recall: 1.0000\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3070 - accuracy: 0.0000e+00 - precision: 0.9233 - recall: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.0000e+00 - val_precision: 0.8529 - val_recall: 1.0000\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.0000e+00 - precision: 0.9475 - recall: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.0000e+00 - val_precision: 0.8529 - val_recall: 1.0000\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3067 - accuracy: 0.0000e+00 - precision: 0.9224 - recall: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.0000e+00 - val_precision: 0.8529 - val_recall: 1.0000\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2813 - accuracy: 0.0000e+00 - precision: 0.9472 - recall: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2949 - accuracy: 0.0000e+00 - precision: 0.9316 - recall: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2727 - accuracy: 0.0000e+00 - precision: 0.9336 - recall: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2769 - accuracy: 0.0000e+00 - precision: 0.9280 - recall: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2635 - accuracy: 0.0000e+00 - precision: 0.9589 - recall: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2642 - accuracy: 0.0000e+00 - precision: 0.9489 - recall: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.0000e+00 - precision: 0.9382 - recall: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.0000e+00 - precision: 0.9399 - recall: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2540 - accuracy: 0.0000e+00 - precision: 0.9422 - recall: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.0000e+00 - precision: 0.9453 - recall: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.0000e+00 - precision: 0.9622 - recall: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2438 - accuracy: 0.0000e+00 - precision: 0.9413 - recall: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2437 - accuracy: 0.0000e+00 - precision: 0.9347 - recall: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2246 - accuracy: 0.0000e+00 - precision: 0.9455 - recall: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.0000e+00 - precision: 0.9455 - recall: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.0000e+00 - val_precision: 0.8923 - val_recall: 1.0000\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2286 - accuracy: 0.0000e+00 - precision: 0.9450 - recall: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.0000e+00 - val_precision: 0.9206 - val_recall: 1.0000\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2231 - accuracy: 0.0000e+00 - precision: 0.9341 - recall: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.0000e+00 - val_precision: 0.9206 - val_recall: 1.0000\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2232 - accuracy: 0.0000e+00 - precision: 0.9386 - recall: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.0000e+00 - val_precision: 0.9206 - val_recall: 1.0000\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2267 - accuracy: 0.0000e+00 - precision: 0.9325 - recall: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.0000e+00 - val_precision: 0.9206 - val_recall: 1.0000\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2064 - accuracy: 0.0000e+00 - precision: 0.9535 - recall: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2023 - accuracy: 0.0000e+00 - precision: 0.9587 - recall: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.0000e+00 - precision: 0.9451 - recall: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1948 - accuracy: 0.0000e+00 - precision: 0.9489 - recall: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2081 - accuracy: 0.0000e+00 - precision: 0.9305 - recall: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.0000e+00 - precision: 0.9408 - recall: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.0000e+00 - precision: 0.9660 - recall: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.0000e+00 - precision: 0.9552 - recall: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1887 - accuracy: 0.0000e+00 - precision: 0.9610 - recall: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.0000e+00 - precision: 0.9525 - recall: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1902 - accuracy: 0.0000e+00 - precision: 0.9555 - recall: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1831 - accuracy: 0.0000e+00 - precision: 0.9555 - recall: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.0000e+00 - precision: 0.9642 - recall: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.0000e+00 - precision: 0.9499 - recall: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.0000e+00 - precision: 0.9521 - recall: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1706 - accuracy: 0.0000e+00 - precision: 0.9669 - recall: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1799 - accuracy: 0.0000e+00 - precision: 0.9506 - recall: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.0000e+00 - precision: 0.9616 - recall: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.0000e+00 - precision: 0.9653 - recall: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1667 - accuracy: 0.0000e+00 - precision: 0.9671 - recall: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 0.0000e+00 - precision: 0.9541 - recall: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1580 - accuracy: 0.0000e+00 - precision: 0.9588 - recall: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.0000e+00 - precision: 0.9347 - recall: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.0000e+00 - precision: 0.9576 - recall: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.0000e+00 - precision: 0.9703 - recall: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.0000e+00 - precision: 0.9601 - recall: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1448 - accuracy: 0.0000e+00 - precision: 0.9782 - recall: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.0000e+00 - precision: 0.9733 - recall: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.0000e+00 - precision: 0.9608 - recall: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1462 - accuracy: 0.0000e+00 - precision: 0.9753 - recall: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.0000e+00 - precision: 0.9489 - recall: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.0000e+00 - precision: 0.9636 - recall: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.0000e+00 - precision: 0.9748 - recall: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1614 - accuracy: 0.0000e+00 - precision: 0.9483 - recall: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.0000e+00 - precision: 0.9575 - recall: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1472 - accuracy: 0.0000e+00 - precision: 0.9558 - recall: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.0000e+00 - precision: 0.9783 - recall: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.0000e+00 - precision: 0.9550 - recall: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.0000e+00 - precision: 0.9605 - recall: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.0000e+00 - precision: 0.9650 - recall: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.0000e+00 - precision: 0.9735 - recall: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.0000e+00 - precision: 0.9815 - recall: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.0000e+00 - val_precision: 0.9355 - val_recall: 1.0000\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.0000e+00 - precision: 0.9550 - recall: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1270 - accuracy: 0.0000e+00 - precision: 0.9747 - recall: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.0000e+00 - precision: 0.9664 - recall: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.0000e+00 - precision: 0.9570 - recall: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1290 - accuracy: 0.0000e+00 - precision: 0.9639 - recall: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1325 - accuracy: 0.0000e+00 - precision: 0.9671 - recall: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.0000e+00 - precision: 0.9716 - recall: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.0000e+00 - precision: 0.9616 - recall: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.0000e+00 - precision: 0.9624 - recall: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.0000e+00 - precision: 0.9790 - recall: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.0000e+00 - precision: 0.9651 - recall: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.0000e+00 - precision: 0.9737 - recall: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.0000e+00 - precision: 0.9665 - recall: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.0000e+00 - val_precision: 0.9508 - val_recall: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjpfrg8WNTW",
        "outputId": "931e64fb-284a-4f42-810d-2b8e5765866f"
      },
      "source": [
        "ensembler_test = np.transpose(np.array([LogReg.predict_proba(x_test)[:,1],RF.predict_proba(x_test)[:,1],KNN.predict_proba(x_test)[:,1]]))\n",
        "acc_DL = (np.array(tf.greater(ensembler.predict(ensembler_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of ensembler model is',acc_DL)\n",
        "acc_LR = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_SK)\n",
        "acc_KNN = (KNN.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of K-nearest neighbors model is',acc_SK)\n",
        "acc_RF = (RF.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Random Forest model is',acc_SK)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of ensembler model is 96.49122807017544\n",
            "Accuracy of Logistic Regression model is 95.6140350877193\n",
            "Accuracy of K-nearest neighbors model is 95.6140350877193\n",
            "Accuracy of Random Forest model is 95.6140350877193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPwavnEAzlhP"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}