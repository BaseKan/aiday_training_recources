{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oplossingen_huiswerk.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZqnFZ6uEhemKKZIsoyeui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaseKan/aiday_training_resources/blob/main/TF_basics/Oplossingen_huiswerk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA-EvZMOuvSp",
        "outputId": "2abd35cf-8624-41bf-8ed4-3f626ba5093a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "print(tf.__version__)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrlqAU4ru70B"
      },
      "source": [
        "**Opdracht een & twee** Train een deep learning model op de Diabetes dataset (met maar een kolom) met maar een Dense laag met maar 1 neuron (unit). Train een lineair regressiemodel met sklearn. Maak daarna een scatterplot van de traindata met op de x-as de eerste kolom van de traindata en op de y-as de y_train. Voeg nu twee lijnen toe die met voorspelling van het sklearn model en het keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bMjyluu6jP"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# we houden voor deze opdracht enkel kolom drie\n",
        "x_train = x_train[:,2]\n",
        "x_test = x_test[:,2]\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(1,))\n",
        "dense = layers.Dense(1)\n",
        "output = dense(input)\n",
        "\n",
        "regressie_model = models.Model(input,output)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression().fit(x_train.reshape(-1,1),y_train)\n",
        "y_SK = lm.predict(x_train.reshape(-1,1))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4HxvAwZQw3pD",
        "outputId": "f672f392-c91c-4323-c34e-4250bf076093"
      },
      "source": [
        "# compilen model\n",
        "rate = 0.5\n",
        "rate_slow = 0.08\n",
        "epochs = 250\n",
        "def schedule(epoch, lr):\n",
        "  if epoch >= 50:\n",
        "    return rate_slow\n",
        "  return rate\n",
        " \n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)\n",
        "\n",
        "regressie_model.compile(optimizer=SGD(lr,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "# callback voor plot\n",
        "\n",
        "class Plot(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, batch, logs={}):\n",
        "    clear_output(wait=True)\n",
        "    y_DL = regressie_model.predict(x_train)\n",
        "    plt.scatter(x_train,y_train)\n",
        "    plt.plot(x_train,y_DL, label='keras')\n",
        "    plt.plot(x_train,y_SK, label='sklearn')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# trainen model\n",
        "history = regressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=x_train.shape[0],\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[scheduler,Plot()]\n",
        "                    )"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUBvTRt7vUgs"
      },
      "source": [
        "**Opdracht drie** Gebruik nu alle diabetesdata en train een lineair regressiemodel. Train nu een deep learning model met betere validatie score. Vergelijke de MSE op de test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3U3SxHPvUtt",
        "outputId": "1f3f0f6b-49d1-4155-be1f-bfde937adfa0"
      },
      "source": [
        "# inladen data\n",
        "data = load_diabetes()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1)(dense1)\n",
        "\n",
        "regressie_model2 = models.Model(input,output)\n",
        "\n",
        "regressie_model2.compile(optimizer=SGD(5e-5,0.9),\n",
        "                        loss='mse')\n",
        "\n",
        "history2 = regressie_model2.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)\n",
        "\n",
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lm2 = LinearRegression().fit(x_train,y_train)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 32568.8496 - val_loss: 21803.4688\n",
            "Epoch 2/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 30895.3003 - val_loss: 15851.0488\n",
            "Epoch 3/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 18395.5994 - val_loss: 15653.3271\n",
            "Epoch 4/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9188.8625 - val_loss: 4457.7905\n",
            "Epoch 5/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6536.0722 - val_loss: 4736.6763\n",
            "Epoch 6/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6047.6363 - val_loss: 5032.1885\n",
            "Epoch 7/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5715.1694 - val_loss: 4017.1101\n",
            "Epoch 8/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5334.6633 - val_loss: 5229.3325\n",
            "Epoch 9/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5123.3100 - val_loss: 4476.3042\n",
            "Epoch 10/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4722.7279 - val_loss: 3629.9893\n",
            "Epoch 11/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4115.0833 - val_loss: 3305.6914\n",
            "Epoch 12/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4195.3390 - val_loss: 5060.0376\n",
            "Epoch 13/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4263.1189 - val_loss: 3252.1628\n",
            "Epoch 14/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3505.5653 - val_loss: 4081.0308\n",
            "Epoch 15/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3567.3173 - val_loss: 3297.0767\n",
            "Epoch 16/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3533.1955 - val_loss: 3455.2747\n",
            "Epoch 17/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3382.9058 - val_loss: 3592.1123\n",
            "Epoch 18/40\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3351.4607 - val_loss: 5189.7979\n",
            "Epoch 19/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4960.3789 - val_loss: 3250.2520\n",
            "Epoch 20/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3164.1474 - val_loss: 3216.9111\n",
            "Epoch 21/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3005.6916 - val_loss: 3297.0386\n",
            "Epoch 22/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3046.6526 - val_loss: 3544.5325\n",
            "Epoch 23/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3729.9151 - val_loss: 3465.9944\n",
            "Epoch 24/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2734.3155 - val_loss: 4373.7681\n",
            "Epoch 25/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4448.6916 - val_loss: 3279.5947\n",
            "Epoch 26/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3128.7813 - val_loss: 4092.7500\n",
            "Epoch 27/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2963.3548 - val_loss: 3675.6431\n",
            "Epoch 28/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3000.0383 - val_loss: 3303.7393\n",
            "Epoch 29/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3045.1852 - val_loss: 3395.2024\n",
            "Epoch 30/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2898.6787 - val_loss: 3362.1770\n",
            "Epoch 31/40\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2721.7077 - val_loss: 3399.9292\n",
            "Epoch 32/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3080.9064 - val_loss: 3583.4243\n",
            "Epoch 33/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3502.0629 - val_loss: 3498.3450\n",
            "Epoch 34/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2956.8024 - val_loss: 3720.5542\n",
            "Epoch 35/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3098.9387 - val_loss: 3368.2546\n",
            "Epoch 36/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2992.1312 - val_loss: 6327.0142\n",
            "Epoch 37/40\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4499.4416 - val_loss: 3292.4683\n",
            "Epoch 38/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2837.5521 - val_loss: 3396.6228\n",
            "Epoch 39/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3284.3521 - val_loss: 3339.3000\n",
            "Epoch 40/40\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2915.5384 - val_loss: 3513.9111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGku2miOwpW",
        "outputId": "62303da9-0de0-4dff-80e1-2906c4b4b59c"
      },
      "source": [
        "print('Linear regression test MSE', np.mean((regressie_model2.predict(x_test)-y_test)**2))\n",
        "print('Deep Learning test MSE',np.mean((lm2.predict(x_test)-y_test)**2))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear regression test MSE 8296.7908898852\n",
            "Deep Learning test MSE 2900.1732878832318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDGkcDYvU0D"
      },
      "source": [
        "**Opdracht vier** Ontwerp en train een meerlaags classificatiemodel op de breast cancer dataset. \n",
        "\n",
        "*   De activatie van je laatste laag moet voor binaire classificatie 'sigmoid' zijn (als er meer dan twee klassen waren geweest hadden we 'softmax' gebruikt)\n",
        "\n",
        "*   Als loss kan je 'binary_crossentropy' gebruiken\n",
        "\n",
        "Er zijn veel metrieken die je kan bekijken, bijvoorbeeld: precision, accuracy, recall, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAt2b6hfvU5p"
      },
      "source": [
        "# inladen data\n",
        "data = load_breast_cancer()\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=42)\n",
        "\n",
        "# definieren model - gebruiken de alternatieve methode van definieren\n",
        "input = layers.Input(shape=(x_train.shape[1],))\n",
        "dense = layers.Dense(64)(input)\n",
        "dense1 = layers.Dense(32)(dense)\n",
        "output = layers.Dense(1,activation='sigmoid')(dense1)\n",
        "\n",
        "logregressie_model = models.Model(input,output)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3F_B5SkRa77",
        "outputId": "a8022934-9067-49de-8545-3a7d697f6cb8"
      },
      "source": [
        "logregressie_model.compile(optimizer=SGD(5e-6,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Accuracy','Precision','Recall']\n",
        ")\n",
        "\n",
        "history2 = logregressie_model.fit(x=x_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "10/10 [==============================] - 1s 46ms/step - loss: 46.1742 - accuracy: 0.5425 - precision: 0.7059 - recall: 0.8391 - val_loss: 7.0678 - val_accuracy: 0.5824 - val_precision: 0.7436 - val_recall: 1.0000\n",
            "Epoch 2/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.7550 - accuracy: 0.4236 - precision: 0.8414 - recall: 0.9223 - val_loss: 3.8960 - val_accuracy: 0.2967 - val_precision: 0.8382 - val_recall: 0.9828\n",
            "Epoch 3/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7821 - accuracy: 0.2960 - precision: 0.8469 - recall: 0.8477 - val_loss: 3.1758 - val_accuracy: 0.1758 - val_precision: 0.8500 - val_recall: 0.8793\n",
            "Epoch 4/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3720 - accuracy: 0.2063 - precision: 0.8844 - recall: 0.8255 - val_loss: 3.3980 - val_accuracy: 0.2308 - val_precision: 0.8462 - val_recall: 0.9483\n",
            "Epoch 5/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3375 - accuracy: 0.2056 - precision: 0.8912 - recall: 0.8619 - val_loss: 3.0370 - val_accuracy: 0.1758 - val_precision: 0.8475 - val_recall: 0.8621\n",
            "Epoch 6/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2362 - accuracy: 0.1853 - precision: 0.9036 - recall: 0.8505 - val_loss: 3.1448 - val_accuracy: 0.1978 - val_precision: 0.8525 - val_recall: 0.8966\n",
            "Epoch 7/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5102 - accuracy: 0.1864 - precision: 0.8923 - recall: 0.8699 - val_loss: 2.9479 - val_accuracy: 0.1209 - val_precision: 0.8679 - val_recall: 0.7931\n",
            "Epoch 8/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2227 - accuracy: 0.2329 - precision: 0.9145 - recall: 0.8446 - val_loss: 3.1221 - val_accuracy: 0.0879 - val_precision: 0.8723 - val_recall: 0.7069\n",
            "Epoch 9/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2654 - accuracy: 0.1881 - precision: 0.9142 - recall: 0.8513 - val_loss: 3.2891 - val_accuracy: 0.2198 - val_precision: 0.8462 - val_recall: 0.9483\n",
            "Epoch 10/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.5322 - accuracy: 0.2249 - precision: 0.8843 - recall: 0.8991 - val_loss: 4.4148 - val_accuracy: 0.4286 - val_precision: 0.8056 - val_recall: 1.0000\n",
            "Epoch 11/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.4013 - accuracy: 0.3318 - precision: 0.8936 - recall: 0.9156 - val_loss: 3.7766 - val_accuracy: 0.0769 - val_precision: 0.9143 - val_recall: 0.5517\n",
            "Epoch 12/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0780 - accuracy: 0.1910 - precision: 0.9366 - recall: 0.7101 - val_loss: 2.8151 - val_accuracy: 0.1648 - val_precision: 0.8621 - val_recall: 0.8621\n",
            "Epoch 13/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2757 - accuracy: 0.2147 - precision: 0.8747 - recall: 0.8387 - val_loss: 5.6541 - val_accuracy: 0.5385 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 14/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6461 - accuracy: 0.3881 - precision: 0.8329 - recall: 0.9228 - val_loss: 4.6200 - val_accuracy: 0.4505 - val_precision: 0.7838 - val_recall: 1.0000\n",
            "Epoch 15/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2581 - accuracy: 0.3656 - precision: 0.8737 - recall: 0.9399 - val_loss: 3.4687 - val_accuracy: 0.2747 - val_precision: 0.8235 - val_recall: 0.9655\n",
            "Epoch 16/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.5630 - accuracy: 0.3097 - precision: 0.8717 - recall: 0.9202 - val_loss: 4.1806 - val_accuracy: 0.4176 - val_precision: 0.7945 - val_recall: 1.0000\n",
            "Epoch 17/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6176 - accuracy: 0.3518 - precision: 0.8667 - recall: 0.8850 - val_loss: 3.2158 - val_accuracy: 0.2418 - val_precision: 0.8333 - val_recall: 0.9483\n",
            "Epoch 18/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9573 - accuracy: 0.2483 - precision: 0.9165 - recall: 0.9095 - val_loss: 3.5685 - val_accuracy: 0.3077 - val_precision: 0.8261 - val_recall: 0.9828\n",
            "Epoch 19/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3505 - accuracy: 0.2768 - precision: 0.8692 - recall: 0.9079 - val_loss: 2.7953 - val_accuracy: 0.1868 - val_precision: 0.8387 - val_recall: 0.8966\n",
            "Epoch 20/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3266 - accuracy: 0.1903 - precision: 0.8808 - recall: 0.8907 - val_loss: 3.0105 - val_accuracy: 0.2198 - val_precision: 0.8462 - val_recall: 0.9483\n",
            "Epoch 21/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2541 - accuracy: 0.1924 - precision: 0.8705 - recall: 0.8733 - val_loss: 2.5933 - val_accuracy: 0.1648 - val_precision: 0.8621 - val_recall: 0.8621\n",
            "Epoch 22/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2573 - accuracy: 0.1921 - precision: 0.9091 - recall: 0.8580 - val_loss: 2.6826 - val_accuracy: 0.0989 - val_precision: 0.8542 - val_recall: 0.7069\n",
            "Epoch 23/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3393 - accuracy: 0.1889 - precision: 0.9321 - recall: 0.8415 - val_loss: 5.2104 - val_accuracy: 0.5165 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 24/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2118 - accuracy: 0.3353 - precision: 0.8132 - recall: 0.9022 - val_loss: 2.5459 - val_accuracy: 0.1209 - val_precision: 0.8704 - val_recall: 0.8103\n",
            "Epoch 25/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2696 - accuracy: 0.1662 - precision: 0.8891 - recall: 0.8300 - val_loss: 5.2951 - val_accuracy: 0.5165 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 26/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2625 - accuracy: 0.3494 - precision: 0.8073 - recall: 0.9207 - val_loss: 2.6785 - val_accuracy: 0.1758 - val_precision: 0.8413 - val_recall: 0.9138\n",
            "Epoch 27/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1504 - accuracy: 0.1797 - precision: 0.8785 - recall: 0.8945 - val_loss: 2.4994 - val_accuracy: 0.1648 - val_precision: 0.8621 - val_recall: 0.8621\n",
            "Epoch 28/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7561 - accuracy: 0.2384 - precision: 0.8692 - recall: 0.8332 - val_loss: 5.3544 - val_accuracy: 0.5275 - val_precision: 0.7532 - val_recall: 1.0000\n",
            "Epoch 29/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7932 - accuracy: 0.3504 - precision: 0.8772 - recall: 0.9391 - val_loss: 2.5414 - val_accuracy: 0.1648 - val_precision: 0.8644 - val_recall: 0.8793\n",
            "Epoch 30/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1588 - accuracy: 0.1839 - precision: 0.9055 - recall: 0.8974 - val_loss: 2.7109 - val_accuracy: 0.1868 - val_precision: 0.8438 - val_recall: 0.9310\n",
            "Epoch 31/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9839 - accuracy: 0.2595 - precision: 0.9263 - recall: 0.9126 - val_loss: 2.4302 - val_accuracy: 0.1648 - val_precision: 0.8596 - val_recall: 0.8448\n",
            "Epoch 32/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0333 - accuracy: 0.1802 - precision: 0.9055 - recall: 0.8693 - val_loss: 2.4611 - val_accuracy: 0.1648 - val_precision: 0.8621 - val_recall: 0.8621\n",
            "Epoch 33/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1155 - accuracy: 0.1992 - precision: 0.9011 - recall: 0.8690 - val_loss: 2.7675 - val_accuracy: 0.1978 - val_precision: 0.8462 - val_recall: 0.9483\n",
            "Epoch 34/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2090 - accuracy: 0.1827 - precision: 0.8947 - recall: 0.8916 - val_loss: 2.7488 - val_accuracy: 0.1978 - val_precision: 0.8462 - val_recall: 0.9483\n",
            "Epoch 35/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1504 - accuracy: 0.2014 - precision: 0.9097 - recall: 0.8930 - val_loss: 2.4749 - val_accuracy: 0.0879 - val_precision: 0.8511 - val_recall: 0.6897\n",
            "Epoch 36/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0928 - accuracy: 0.1758 - precision: 0.9037 - recall: 0.8033 - val_loss: 2.8655 - val_accuracy: 0.2198 - val_precision: 0.8235 - val_recall: 0.9655\n",
            "Epoch 37/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9137 - accuracy: 0.2206 - precision: 0.9004 - recall: 0.9304 - val_loss: 2.3562 - val_accuracy: 0.1538 - val_precision: 0.8621 - val_recall: 0.8621\n",
            "Epoch 38/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9159 - accuracy: 0.1831 - precision: 0.9221 - recall: 0.8821 - val_loss: 2.6362 - val_accuracy: 0.0769 - val_precision: 0.8837 - val_recall: 0.6552\n",
            "Epoch 39/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6823 - accuracy: 0.2078 - precision: 0.8996 - recall: 0.7377 - val_loss: 2.2959 - val_accuracy: 0.1099 - val_precision: 0.8654 - val_recall: 0.7759\n",
            "Epoch 40/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4686 - accuracy: 0.1841 - precision: 0.8926 - recall: 0.8082 - val_loss: 4.7613 - val_accuracy: 0.4945 - val_precision: 0.7532 - val_recall: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahpahNKrQn-k",
        "outputId": "c17b337f-e002-4b20-d08b-3558f9ed071b"
      },
      "source": [
        "# definieren sklearn model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LogReg = LogisticRegression().fit(x_train,y_train)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxHUxcP9SCLX",
        "outputId": "72b69919-0b6c-4e0f-ce4d-d68acc42426e"
      },
      "source": [
        "acc_DL = (np.array(tf.greater(regressie_model2.predict(x_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of deep learning model is',acc_DL)\n",
        "acc_SK = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_SK)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of deep learning model is 86.8421052631579\n",
            "Accuracy of Logistic Regression model is 96.49122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvQQR6nvU_y"
      },
      "source": [
        "**Bonus: ensembling/stacking** Laten we kijken of we met stacking het bovenstaande deep learning model kunnen verslaan. Bij ensemblen trainen we in dit geval een netwerk met maar een laag, die de optimale combinatie van voorspelling zoekt van andere modellen. Doorloop de volgende 3 stappen:\n",
        "1. Train drie verschillende classificatiemodellen met sklearn, bijvoorbeeld randomforest, logistic regression en KNN\n",
        "2. Maak een nieuw numpy array met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_train. \n",
        "3. Gebruik dit nieuwe dataframe als input voor een eenlaags neuraal netwerk met 1 neuron (zoals we bij opdracht een hadden ontworpen). De labels blijven natuurlijk y_train. \n",
        "\n",
        "Gefeliciteerd je hebt nu een ensemble model getraind! Om te testen of dit model beter werkt dan je deep learning model moet je nog 2 stappen doorlopen.\n",
        "\n",
        "i. Maak een nieuw dataframe met 3 kolommen, waar elke kolom de voorspellingen bevat van de drie sklearn modellen op de dataset x_test.\n",
        "\n",
        "ii. Doe model.predict op deze nieuwe dataset en bereken handmatig de loss en metrieken. \n",
        "\n",
        "*Nota bene: je kan de resultaten nog verder verbeteren door 4 modellen te ensemblen, waarvan het vierde model je deep learning model uit opdracht 3 is*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIca6LiuvVGS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "RF = RandomForestClassifier().fit(x_train,y_train)\n",
        "KNN = KNeighborsClassifier(n_neighbors=3).fit(x_train,y_train)\n",
        "\n",
        "ensemble_train = np.transpose(np.array([LogReg.predict(x_train),RF.predict(x_train),KNN.predict(x_train)]))"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk3AOEB2UxCA",
        "outputId": "6783ac08-ca52-4b9c-edc2-92cf269b4534"
      },
      "source": [
        "ensembler = models.Sequential()\n",
        "ensembler.add(layers.Input(shape=(3)))\n",
        "ensembler.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ensembler.compile(optimizer=SGD(1e-2,0.7),\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['Accuracy','Precision','Recall']\n",
        ")\n",
        "                  \n",
        "ensembler_history = ensembler.fit(x=ensemble_train,\n",
        "                    y=y_train,\n",
        "                    batch_size=40,\n",
        "                    epochs=40,\n",
        "                     validation_split=0.2)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "10/10 [==============================] - 1s 46ms/step - loss: 0.6837 - accuracy: 0.0000e+00 - precision: 0.5403 - recall: 0.4260 - val_loss: 0.6288 - val_accuracy: 0.0000e+00 - val_precision: 0.6744 - val_recall: 1.0000\n",
            "Epoch 2/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.0000e+00 - precision: 0.6393 - recall: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 3/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5525 - accuracy: 0.0000e+00 - precision: 0.6475 - recall: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 4/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5258 - accuracy: 0.0000e+00 - precision: 0.5978 - recall: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 5/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.0000e+00 - precision: 0.6317 - recall: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 6/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.0000e+00 - precision: 0.6168 - recall: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 7/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.0000e+00 - precision: 0.6535 - recall: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 8/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.0000e+00 - precision: 0.6412 - recall: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.0000e+00 - val_precision: 0.6374 - val_recall: 1.0000\n",
            "Epoch 9/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.0000e+00 - precision: 0.7561 - recall: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 10/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.0000e+00 - precision: 0.9229 - recall: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 11/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.0000e+00 - precision: 0.9440 - recall: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 12/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.0000e+00 - precision: 0.9557 - recall: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 13/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.0000e+00 - precision: 0.9350 - recall: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 14/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.0000e+00 - precision: 0.9293 - recall: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 15/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.0000e+00 - precision: 0.9311 - recall: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 16/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.0000e+00 - precision: 0.9458 - recall: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 17/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.0000e+00 - precision: 0.9514 - recall: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 18/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.0000e+00 - precision: 0.9290 - recall: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 19/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.0000e+00 - precision: 0.9334 - recall: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 20/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.0000e+00 - precision: 0.9421 - recall: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 21/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3120 - accuracy: 0.0000e+00 - precision: 0.9216 - recall: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 22/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3046 - accuracy: 0.0000e+00 - precision: 0.9366 - recall: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 23/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3059 - accuracy: 0.0000e+00 - precision: 0.9254 - recall: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 24/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2841 - accuracy: 0.0000e+00 - precision: 0.9380 - recall: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 25/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2765 - accuracy: 0.0000e+00 - precision: 0.9495 - recall: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 26/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2829 - accuracy: 0.0000e+00 - precision: 0.9490 - recall: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 27/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2655 - accuracy: 0.0000e+00 - precision: 0.9554 - recall: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 28/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2548 - accuracy: 0.0000e+00 - precision: 0.9513 - recall: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 29/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2725 - accuracy: 0.0000e+00 - precision: 0.9242 - recall: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 30/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2603 - accuracy: 0.0000e+00 - precision: 0.9385 - recall: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 31/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2552 - accuracy: 0.0000e+00 - precision: 0.9461 - recall: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 32/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.0000e+00 - precision: 0.9357 - recall: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 33/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2428 - accuracy: 0.0000e+00 - precision: 0.9342 - recall: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 34/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.0000e+00 - precision: 0.9392 - recall: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 35/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2313 - accuracy: 0.0000e+00 - precision: 0.9413 - recall: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 36/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2276 - accuracy: 0.0000e+00 - precision: 0.9428 - recall: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 37/40\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.0000e+00 - precision: 0.9220 - recall: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 38/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2240 - accuracy: 0.0000e+00 - precision: 0.9440 - recall: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 39/40\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2200 - accuracy: 0.0000e+00 - precision: 0.9352 - recall: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.0000e+00 - val_precision: 0.8788 - val_recall: 1.0000\n",
            "Epoch 40/40\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2198 - accuracy: 0.0000e+00 - precision: 0.9498 - recall: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.0000e+00 - val_precision: 0.9206 - val_recall: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjpfrg8WNTW",
        "outputId": "418104cb-bae6-4363-c118-3bda87b8188d"
      },
      "source": [
        "ensembler_test = np.transpose(np.array([LogReg.predict(x_test),RF.predict(x_test),KNN.predict(x_test)]))\n",
        "acc_DL = (np.array(tf.greater(ensembler.predict(ensembler_test),.5)).flatten().astype('int') == y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of ensembler model is',acc_DL)\n",
        "acc_LR = (LogReg.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Logistic Regression model is',acc_SK)\n",
        "acc_KNN = (KNN.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of K-nearest neighbors model is',acc_SK)\n",
        "acc_RF = (RF.predict(x_test)==y_test).sum()/y_test.shape[0]*100\n",
        "print('Accuracy of Random Forest model is',acc_SK)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of ensembler model is 96.49122807017544\n",
            "Accuracy of Logistic Regression model is 96.49122807017544\n",
            "Accuracy of K-nearest neighbors model is 96.49122807017544\n",
            "Accuracy of Random Forest model is 96.49122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}